<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2020/04/24/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Neural Approaches to Conversational AI</title>
    <url>/2020/04/25/Neural-Approaches-to-Conversational-AI/</url>
    <content><![CDATA[<h3 id="What’s-new"><a href="#What’s-new" class="headerlink" title="What’s new?"></a>What’s new?</h3><ol>
<li><strong>We group conversational systems into three categories: (1) question answering agents, (2) task-oriented dialogue agents, and (3)chatbots, with a unified view of optimal decision making</strong></li>
<li><strong>Draw connections between neural approaches to traditional ones</strong></li>
<li><strong>Present approaches to training dialogue agents using both supervised and reinforcement(++) learning.</strong></li>
<li><strong>Progress and challenges both in rearch community and industry.</strong></li>
</ol>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li><p>Why we get promising results?</p>
<ol>
<li>large amounts of data available for training.</li>
<li>breakthroughs in deep learning and reinforcement learning.</li>
</ol>
</li>
<li><p>A typical task-oriented dialogue agent is composed of four modules:<br>  <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587927050/1111_zxlmue.png" alt=""></p>
<ol>
<li>NLU(Understanding): identify user intents, extract associate info.</li>
<li>State Tracker: capture all essential info, track the dialogue state.</li>
<li>Dialogue Policy: select the next action based on the current state.</li>
<li>NLG(Generation): convert agent actions to natural language responses.</li>
</ol>
<ul>
<li>But recent trend: Develope fully data-driven systems by unifying these modules using a deep neural network that maps the user input to the agent output DIRECTLY.</li>
</ul>
</li>
<li><p>Difference in modular or not:</p>
<ul>
<li>Task-oriented bots:<ul>
<li>access to an external database</li>
<li>using a modular system</li>
</ul>
</li>
<li>Social chatbots:<ul>
<li>To be AI companions to humans with an emotional connection</li>
<li>mimic human conversation by training DNN-based response generation models on large amounts of human-human conversational data.</li>
<li>non-modular system</li>
</ul>
</li>
</ul>
</li>
<li><p>Dialogue can be formulated as a decision making process.</p>
<ul>
<li>hierarchy<ul>
<li>top level: selects what agent be active</li>
<li>low level: chooses primitive actions to complete the subtask</li>
</ul>
</li>
<li>Hierachical decision making processes can be cast in options over Markov Decision Processes(Sutton et al)<ul>
<li>This view has already been applied to some large-scale open-domain dialogue systems.</li>
</ul>
</li>
<li>If we view each option as an action, both top and low level processes can be natually captured by the reinforcement learning framework.<ul>
<li>Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.</li>
<li>The goal of dialogue learning is to find optimal policies to maximize expected rewards.</li>
<li>rewards functions:<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587945852/222_ctrk2x.png" alt=""></li>
<li><strong>controdictary rewards CPS for xiaoice?</strong><ul>
<li>Although incorporating many task-oriented and QA skills can reduce CPS in the short term since these skills help users accomplish tasks more efficiently by minimizing CPS, these new skills establish XiaoIce as an efficient and trustworthy personal assistant, thus strengthening the emotional bond with human users in the long run.</li>
</ul>
</li>
<li>limit of RL view:<ul>
<li>applying RL requires training the agents by interacting with real users, which can be expensive in many domains.</li>
<li>solution<ul>
<li>hybrid approach: combines the strengths of different ML methods.</li>
<li>For example, we might use imitation and/or supervised learning methods (if there is a large amount of human-human conversational corpus) to obtain a reasonably good agent before applying RL to continue improving it.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Symbolic V.S Neural approaches<br>  <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587950076/333_jcwtrl.png" alt=""></p>
<ul>
<li><p><strong>neural approaches</strong>:</p>
<ul>
<li><strong>can be trained in an end-to-end fasion</strong></li>
<li><strong>robust to paraphrase alternations(detecting and generating paraphrases)</strong></li>
<li><strong>weak in terms of execution efficiency and explicit interpretability</strong></li>
</ul>
</li>
<li><p><strong>symbolic approaches</strong></p>
<ul>
<li><strong>sensitive to paraphrase alternations</strong></li>
<li><strong>more interpretable and efficient in execution.</strong></li>
<li><strong>difficult to train</strong></li>
</ul>
</li>
<li><p>Symbolic approaches</p>
<ul>
<li>dominated for decades</li>
<li>resolve natural language ambiguity at different levels by mapping (or generating) a natural language sentence to (or from) a series of human-defined, unambiguous, symbolic representations, such as Part-Of-Speech (POS) tags, context free grammar, first-order predicate calculus.</li>
<li>now: have been adapted as a rich source of engineered features to be fed into a variety of machine learning models</li>
</ul>
</li>
<li><p>neural approaches</p>
<ul>
<li>do not rely on any human-defined symbolic representations</li>
<li>learn in a task- specific neural space where task-specific knowledge is implicitly represented as semantic concepts using low-dimensional continuous vectors.</li>
<li>steps:<ol>
<li>encoding symbolic user input and knowledge into their neural sematic representations( represent as vectors)</li>
<li>reasoning: to generate a system response based on input and system state.</li>
<li>decoding</li>
</ol>
<ul>
<li>the above three steps are stacked into a deep neural network trained in an end-to-end fastionl via back propagation.<ul>
<li>back propagation:<ul>
<li>a widely used algorithm in training feedforward neural networks for supervised learning. </li>
<li>In fitting a neural network, backpropagation computes the gradient of the loss function with respect to the weights of the network for a single input–output example, and does so efficiently, unlike a naive direct computation of the gradient with respect to each weight individually.</li>
<li>The backpropagation algorithm works by computing the gradient of the loss function with respect to each weight by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this is an example of dynamic programming.</li>
</ul>
</li>
<li>end-to-end causes: the focus has shifted to carefully tailoring the increasingly complex architecture of neural networks to the end application.</li>
</ul>
</li>
</ul>
</li>
<li>review: Although neural approaches have already been widely adopted in many AI tasks, including image processing, speech recognition and machine translation (e.g., Goodfellow et al., 2016), their impact on conversational AI has come somewhat more slowly.</li>
<li>addition merits: neural approaches provide a consistent representation for many modalities, capturing linguistic and non-linguistic (e.g., image and video (Mostafazadeh et al., 2017)) features in the same modeling framework.</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning Basics for Conversational AI</title>
    <url>/2020/04/26/Machine-Learning-Basics/</url>
    <content><![CDATA[<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><ul>
<li><strong>Mitchell</strong> defines: any computer program that improves its performance at some task T, measured by P, through experiences E.<ul>
<li>T:(in conversational AI: perform conversations with a user to fulfill the user’s goal.</li>
<li>P: cumulative reward<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587945852/222_ctrk2x.png" alt=""></li>
<li>E: a set of dialogues</li>
</ul>
</li>
</ul>
<h2 id="Surpervised-Learning"><a href="#Surpervised-Learning" class="headerlink" title="Surpervised Learning"></a>Surpervised Learning</h2><ul>
<li>A common recipe of building an ML agent using supervised learning (SL) consists of <ul>
<li>a dataset <ul>
<li>The dataset consists of (x, y∗) pairs, where for each input x, there is a ground-truth output y∗. In QA, x consists of an input question and the documents from which an answer is generated, and y∗ is the desired answer provided by a knowledgeable external supervisor</li>
</ul>
</li>
<li>a model</li>
<li>a cost function (a.k.a. loss function)<ul>
<li>The cost function is of the form L(y∗, f(x; θ))</li>
<li>L(.) is often designed as a smooth function(differentiable everywhere) of error.</li>
<li>A commonly used cost function that meets these criteria is the mean squared error (MSE)<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588012080/de_bccc3c.png" alt=""></li>
</ul>
</li>
<li>an optimization procedure<ul>
<li>The optimization can be viewed as a search algorithm to identify the best θ that <strong>minimize L(.)</strong>. </li>
<li>Given that L is differentiable, the most widely used optimization procedure for deep learning is mini-batch Stochastic Gradient Descent (SGD) which updates θ after each batch as <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588012262/SGD_yin3qj.png" alt=""> where N is the batch size and α the learning rate.</li>
</ul>
</li>
</ul>
</li>
<li>Common supervised learning <strong>metrics</strong><ul>
<li>regression problems: mean squared error<ul>
<li><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588046494/MSE_uncxsu.png" alt=""></li>
</ul>
</li>
<li>classification problems<ul>
<li>binary classification: accuracy, precision, recall, F1 Score<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588048090/binary-classification-metrics_kefszn.png" alt=""></li>
<li>beyond binary: BLEU score</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><ul>
<li>Define: In unexplored territories, the agent has to learn how to act by interacting with an unknown environment on its own. </li>
<li>RL V.S SL:<ul>
<li>While SL learns from previous experiences provided by a knowledgeable external supervisor, RL learns by experiencing on its own.</li>
</ul>
</li>
<li>Feature of RL:<ol>
<li>Exploration-exploitation tradeoff. (???)<ul>
<li>exploit: The agent has to exploit what it already knows in order to obtain high rewards.</li>
<li>explore: The agent has to explore unknown states and actions in order to make better action selections in the future.</li>
</ul>
</li>
<li>Delayed reward and temporal credit assignment. <ul>
<li>The agent has to determine which of the actions in its sequence are to be credited with producing the eventual reward.</li>
</ul>
</li>
<li>Partially observed states. <ul>
<li>In many RL problems, the observation perceived from the environment at each step, e.g., user input in each dialogue turn, provides only partial information about the entire state of the environment based on which the agent selects the next action. </li>
<li>Neural approaches learn a deep neural network to represent the state by <strong>encoding all information</strong> observed at the current and past steps.</li>
</ul>
</li>
</ol>
</li>
<li>A central challenge in both RL and SL: <strong>generalization</strong><ul>
<li>the ability to perform well on unseen inputs.</li>
<li>solution: neural approaches provide a potentially more effective solution by <strong>leveraging the representation</strong>(?) learning power of deep neural networks.</li>
</ul>
</li>
</ul>
<h1 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h1><ul>
<li><p><strong>Deep learning V.S neural network?</strong></p>
<ul>
<li>DL involves training neural networks.</li>
<li><strong>Why Deep?</strong><ul>
<li>The neural networks, in their original form, consisted of a single layer(i.e., the perceptron).</li>
<li>The perceptron is incapable of learning even simple functions such as logical XOR.</li>
<li>To solve the problem, we add hidden layers(<strong>Why hiden?</strong>) between input and output. –this is called MLP(multi-layer perceptron) or DNN(deep neural networks).</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>commonly used DNNs for NLP &amp; IR</strong></p>
<h2 id="Softmax-function"><a href="#Softmax-function" class="headerlink" title="Softmax function"></a><strong>Softmax function</strong></h2></li>
<li><p>An activation function.</p>
</li>
<li><p>It outputs a vector that represents the probability distributions of a list of potential outcomes.</p>
<h3 id="normalization-step-taking-exponentials-sums-and-division"><a href="#normalization-step-taking-exponentials-sums-and-division" class="headerlink" title="normalization step: taking exponentials, sums and division."></a>normalization step: taking exponentials, sums and division.</h3></li>
<li><p>ex. Softmax function turns logits [2.0, 1.0, 0.1] into probabilities [0.7, 0.2, 0.1], and the probabilities sum to 1.</p>
</li>
<li><p><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588104301/softmax_wy6yoa.png" alt=""></p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">logits &#x3D; [2.0, 1.0, 0.1]</span><br><span class="line">exps &#x3D; [np.exp(i) for i in logits]</span><br><span class="line">sum_of_exps &#x3D; sum(exps)</span><br><span class="line">softmax &#x3D; [j&#x2F;sum_of_exps for j in exps]</span><br><span class="line">print(&quot;softmax:&#123;&#125;&quot;.format(softmax))</span><br></pre></td></tr></table></figure>

<ul>
<li><em>Why we need exponents?</em><ul>
<li>Logits ranges from negative infinity to positive infinity. When logits are negative, adding it together does not give us the correct normalization. Exponentiate logitsturn them them zero or positive!</li>
</ul>
</li>
<li><em>Why special number e?</em><ul>
<li>e exponents also makes the math easier later! log(a*b)= log(a)+log(b)</li>
</ul>
</li>
<li><em>logits layer means the last neuron layer of neural network for classification task which produces raw prediction values.</em></li>
<li><em>Logits: numeric output of the last linear layer of a multi-class classification neural network. Before activation takes place.</em></li>
<li>Softmax function is <em>frequently appended to</em> the last layer of an image classification network such as cnn.<ul>
<li><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588105160/soft2_a3nsm6.png" alt=""></li>
</ul>
</li>
</ul>
<h2 id="classical-ML-V-S-DL"><a href="#classical-ML-V-S-DL" class="headerlink" title="classical-ML V.S DL"></a>classical-ML V.S DL</h2><ul>
<li><p><em>Ex: text classification</em></p>
</li>
<li><p>classical ML:</p>
<ol>
<li>Map a text string to a vector representation <strong>x</strong>, using a set of <strong>hand-engineered</strong> features.</li>
<li>Learn a linear classifier with a softmax layer to compute the distribution.<ul>
<li><strong>Design effort: feature engineering</strong></li>
</ul>
</li>
</ol>
</li>
<li><p>DL: Jointly optimize the <em>feature representation</em> and <em>classification</em> using a DNN.</p>
<ul>
<li><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588128439/ml-vs-dl_nel4rq.png" alt=""></li>
<li>DNN consists of two halves:<ol>
<li>top half: linear classifier, similar to classical ML.</li>
<li>The input vector of top half is <strong>not from hand-engineered features</strong>, but learned using the bottom half of the DNN.</li>
</ol>
<ul>
<li>**Design Effort: optimize DNN architectures for effective representation learning.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Which-NN-neural-network-to-choose"><a href="#Which-NN-neural-network-to-choose" class="headerlink" title="Which NN(neural network) to choose?"></a>Which NN(neural network) to choose?</h2><ul>
<li>**Depend on the type of linguistic structures that we hope to capture in the text.<h3 id="Word-Embedding-layers"><a href="#Word-Embedding-layers" class="headerlink" title="Word Embedding layers"></a>Word Embedding layers</h3><h4 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h4></li>
<li>Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.</li>
</ul>
]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
</search>
