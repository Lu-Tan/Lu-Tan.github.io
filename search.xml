<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2020/04/25/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Neural Approaches to Conversational AI</title>
    <url>/2020/04/26/Neural-Approaches-to-Conversational-AI/</url>
    <content><![CDATA[<h3 id="Whatâ€™s-new"><a href="#Whatâ€™s-new" class="headerlink" title="Whatâ€™s new?"></a>Whatâ€™s new?</h3><ol>
<li><strong>We group conversational systems into three categories: (1) question answering agents, (2) task-oriented dialogue agents, and (3)chatbots, with a unified view of optimal decision making</strong></li>
<li><strong>Draw connections between neural approaches to traditional ones</strong></li>
<li><strong>Present approaches to training dialogue agents using both supervised and reinforcement(++) learning.</strong></li>
<li><strong>Progress and challenges both in research community and industry.</strong></li>
</ol>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li><p>Why we get promising results?</p>
<ol>
<li>large amounts of data available for training.</li>
<li>breakthroughs in deep learning and reinforcement learning.</li>
</ol>
</li>
<li><p>A typical task-oriented dialogue agent is composed of four modules:<br>  <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587927050/1111_zxlmue.png" alt=""></p>
<ol>
<li>NLU(Understanding): identify user intents, extract associate info.</li>
<li>State Tracker: capture all essential info, track the dialogue state.</li>
<li>Dialogue Policy: select the next action based on the current state.</li>
<li>NLG(Generation): convert agent actions to natural language responses.</li>
</ol>
<ul>
<li>But recent trend: Develope fully data-driven systems by unifying these modules using a deep neural network that maps the user input to the agent output DIRECTLY.</li>
</ul>
</li>
<li><p>Difference in modular or not:</p>
<ul>
<li>Task-oriented bots:<ul>
<li>access to an external database</li>
<li>using a modular system</li>
</ul>
</li>
<li>Social chatbots:<ul>
<li>To be AI companions to humans with an emotional connection</li>
<li>mimic human conversation by training DNN-based response generation models on large amounts of human-human conversational data.</li>
<li>non-modular system</li>
</ul>
</li>
</ul>
</li>
<li><p>Dialogue can be formulated as a decision making process.</p>
<ul>
<li>hierarchy<ul>
<li>top level: selects what agent be active</li>
<li>low level: chooses primitive actions to complete the subtask</li>
</ul>
</li>
<li>Hierachical decision making processes can be cast in options over Markov Decision Processes(Sutton et al)<ul>
<li>This view has already been applied to some large-scale open-domain dialogue systems.</li>
</ul>
</li>
<li>If we view each option as an action, both top and low level processes can be natually captured by the reinforcement learning framework.<ul>
<li>Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.</li>
<li>The goal of dialogue learning is to find optimal policies to maximize expected rewards.</li>
<li>rewards functions:<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587945852/222_ctrk2x.png" alt=""></li>
<li><strong>controdictary rewards CPS for xiaoice?</strong><ul>
<li>Although incorporating many task-oriented and QA skills can reduce CPS in the short term since these skills help users accomplish tasks more efficiently by minimizing CPS, these new skills establish XiaoIce as an efficient and trustworthy personal assistant, thus strengthening the emotional bond with human users in the long run.</li>
</ul>
</li>
<li>limit of RL view:<ul>
<li>applying RL requires training the agents by interacting with real users, which can be expensive in many domains.</li>
<li>solution<ul>
<li>hybrid approach: combines the strengths of different ML methods.</li>
<li>For example, we might use imitation and/or supervised learning methods (if there is a large amount of human-human conversational corpus) to obtain a reasonably good agent before applying RL to continue improving it.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Symbolic V.S Neural approaches<br>  <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587950076/333_jcwtrl.png" alt=""></p>
<ul>
<li><p><strong>neural approaches</strong>:</p>
<ul>
<li><strong>can be trained in an end-to-end fasion</strong></li>
<li><strong>robust to paraphrase alternations(detecting and generating paraphrases)</strong></li>
<li><strong>weak in terms of execution efficiency and explicit interpretability</strong></li>
</ul>
</li>
<li><p><strong>symbolic approaches</strong></p>
<ul>
<li><strong>sensitive to paraphrase alternations</strong></li>
<li><strong>more interpretable and efficient in execution.</strong></li>
<li><strong>difficult to train</strong></li>
</ul>
</li>
<li><p>Symbolic approaches</p>
<ul>
<li>dominated for decades</li>
<li>resolve natural language ambiguity at different levels by mapping (or generating) a natural language sentence to (or from) a series of human-defined, unambiguous, symbolic representations, such as Part-Of-Speech (POS) tags, context free grammar, first-order predicate calculus.</li>
<li>now: have been adapted as a rich source of engineered features to be fed into a variety of machine learning models</li>
</ul>
</li>
<li><p>neural approaches</p>
<ul>
<li>do not rely on any human-defined symbolic representations</li>
<li>learn in a task- specific neural space where task-specific knowledge is implicitly represented as semantic concepts using low-dimensional continuous vectors.</li>
<li>steps:<ol>
<li>encoding symbolic user input and knowledge into their neural sematic representations( represent as vectors)</li>
<li>reasoning: to generate a system response based on input and system state.</li>
<li>decoding</li>
</ol>
<ul>
<li>the above three steps are stacked into a deep neural network trained in an end-to-end fastionl via back propagation.<ul>
<li>back propagation:<ul>
<li>a widely used algorithm in training feedforward neural networks for supervised learning. </li>
<li>In fitting a neural network, backpropagation computes the gradient of the loss function with respect to the weights of the network for a single inputâ€“output example, and does so efficiently, unlike a naive direct computation of the gradient with respect to each weight individually.</li>
<li>The backpropagation algorithm works by computing the gradient of the loss function with respect to each weight by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this is an example of dynamic programming.</li>
</ul>
</li>
<li>end-to-end causes: the focus has shifted to carefully tailoring the increasingly complex architecture of neural networks to the end application.</li>
</ul>
</li>
</ul>
</li>
<li>review: Although neural approaches have already been widely adopted in many AI tasks, including image processing, speech recognition and machine translation (e.g., Goodfellow et al., 2016), their impact on conversational AI has come somewhat more slowly.</li>
<li>addition merits: neural approaches provide a consistent representation for many modalities, capturing linguistic and non-linguistic (e.g., image and video (Mostafazadeh et al., 2017)) features in the same modeling framework.</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning Basics for Conversational AI</title>
    <url>/2020/04/27/Machine-Learning-Basics/</url>
    <content><![CDATA[<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p><strong>Mitchell</strong> defines: any computer program that improves its performance at some task T, measured by P, through experiences E.</p>
<ul>
<li>T:(in conversational AI: perform conversations with a user to fulfill the userâ€™s goal.</li>
<li>P: cumulative reward<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587945852/222_ctrk2x.png" alt=""></li>
<li>E: a set of dialogues</li>
</ul>
<h2 id="Surpervised-Learning"><a href="#Surpervised-Learning" class="headerlink" title="Surpervised Learning"></a>Surpervised Learning</h2><h4 id="A-common-recipe-of-building-an-ML-agent-using-supervised-learning-SL-consists-of"><a href="#A-common-recipe-of-building-an-ML-agent-using-supervised-learning-SL-consists-of" class="headerlink" title="A common recipe of building an ML agent using supervised learning (SL) consists of"></a>A common recipe of building an ML agent using supervised learning (SL) consists of</h4><ul>
<li>a dataset </li>
<li>The dataset consists of (x, yâˆ—) pairs, where for each input x, there is a ground-truth output yâˆ—. In QA, x consists of an input question and the documents from which an answer is generated, and yâˆ— is the desired answer provided by a knowledgeable external supervisor</li>
<li>a model</li>
<li>a cost function (a.k.a. loss function)<ul>
<li>The cost function is of the form L(yâˆ—, f(x; Î¸))</li>
<li>L(.) is often designed as a smooth function(differentiable everywhere) of error.</li>
<li>A commonly used cost function that meets these criteria is the mean squared error (MSE)<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588012080/de_bccc3c.png" alt=""></li>
</ul>
</li>
<li>an optimization procedure<ul>
<li>The optimization can be viewed as a search algorithm to identify the best Î¸ that <strong>minimize L(.)</strong>.<br>Given that L is differentiable, the most widely used optimization procedure for deep learning is mini-batch Stochastic Gradient Descent (SGD) which updates Î¸ after each batch as <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588012262/SGD_yin3qj.png" alt=""> where N is the batch size and Î± the learning rate.</li>
</ul>
</li>
</ul>
<h4 id="Common-supervised-learning-metrics"><a href="#Common-supervised-learning-metrics" class="headerlink" title="Common supervised learning metrics"></a>Common supervised learning <strong>metrics</strong></h4><p>regression problems: mean squared error</p>
<ul>
<li><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588046494/MSE_uncxsu.png" alt=""></li>
</ul>
<p>classification problems</p>
<ul>
<li>binary classification: accuracy, precision, recall, F1 Score<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588048090/binary-classification-metrics_kefszn.png" alt=""></li>
<li>beyond binary: BLEU score</li>
</ul>
<h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><p>Define: In unexplored territories, the agent has to learn how to act by interacting with an unknown environment on its own. </p>
<h4 id="RL-V-S-SL"><a href="#RL-V-S-SL" class="headerlink" title="RL V.S SL:"></a>RL V.S SL:</h4><p>While SL learns from previous experiences provided by a knowledgeable external supervisor, RL learns by experiencing on its own.</p>
<h4 id="Feature-of-RL"><a href="#Feature-of-RL" class="headerlink" title="Feature of RL:"></a>Feature of RL:</h4><ol>
<li>Exploration-exploitation tradeoff. (???)</li>
</ol>
<ul>
<li>exploit: The agent has to exploit what it already knows in order to obtain high rewards.</li>
<li>explore: The agent has to explore unknown states and actions in order to make better action selections in the future.</li>
</ul>
<ol start="2">
<li><p>Delayed reward and temporal credit assignment.<br>The agent has to determine which of the actions in its sequence are to be credited with producing the eventual reward.</p>
</li>
<li><p>Partially observed states.<br>In many RL problems, the observation perceived from the environment at each step, e.g., user input in each dialogue turn, provides only partial information about the entire state of the environment based on which the agent selects the next action.<br>Neural approaches learn a deep neural network to represent the state by <strong>encoding all information</strong> observed at the current and past steps.</p>
</li>
</ol>
<h4 id="A-central-challenge-in-both-RL-and-SL-generalization"><a href="#A-central-challenge-in-both-RL-and-SL-generalization" class="headerlink" title="A central challenge in both RL and SL: generalization"></a>A central challenge in both RL and SL: <strong>generalization</strong></h4><p>the ability to perform well on unseen inputs.</p>
<ul>
<li>solution: neural approaches provide a potentially more effective solution by <strong>leveraging the representation</strong>(?) learning power of deep neural networks.</li>
</ul>
<h1 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h1><h4 id="Deep-learning-V-S-neural-network"><a href="#Deep-learning-V-S-neural-network" class="headerlink" title="Deep learning V.S neural network?"></a>Deep learning V.S neural network?</h4><p>DL involves training neural networks.</p>
<p><strong>Why Deep?</strong></p>
<p>The neural networks, in their original form, consisted of a single layer(i.e., the perceptron).</p>
<p>The perceptron is incapable of learning even simple functions such as logical XOR.</p>
<p>To solve the problem, we add hidden layers(<strong>Why hiden?</strong>) between input and output. â€“this is called MLP(multi-layer perceptron) or DNN(deep neural networks).</p>
<h2 id="commonly-used-DNNs-for-NLP-amp-IR"><a href="#commonly-used-DNNs-for-NLP-amp-IR" class="headerlink" title="commonly used DNNs for NLP &amp; IR"></a>commonly used DNNs for NLP &amp; IR</h2><h3 id="Softmax-function"><a href="#Softmax-function" class="headerlink" title="Softmax function"></a><strong>Softmax function</strong></h3><p>An activation function.</p>
<p>It outputs a vector that represents the probability distributions of a list of potential outcomes.</p>
<h3 id="normalization-step-taking-exponentials-sums-and-division"><a href="#normalization-step-taking-exponentials-sums-and-division" class="headerlink" title="normalization step: taking exponentials, sums and division."></a><strong>normalization step: taking exponentials, sums and division.</strong></h3><p>ex. Softmax function turns logits [2.0, 1.0, 0.1] into probabilities [0.7, 0.2, 0.1], and the probabilities sum to 1.<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588104301/softmax_wy6yoa.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">logits &#x3D; [2.0, 1.0, 0.1]</span><br><span class="line">exps &#x3D; [np.exp(i) for i in logits]</span><br><span class="line">sum_of_exps &#x3D; sum(exps)</span><br><span class="line">softmax &#x3D; [j&#x2F;sum_of_exps for j in exps]</span><br><span class="line">print(&quot;softmax:&#123;&#125;&quot;.format(softmax))</span><br></pre></td></tr></table></figure>

<p><em>Why we need exponents?</em></p>
<ul>
<li>Logits ranges from negative infinity to positive infinity. When logits are negative, adding it together does not give us the correct normalization. Exponentiate logitsturn them them zero or positive!</li>
</ul>
<p><em>Why special number e?</em></p>
<ul>
<li>e exponents also makes the math easier later! log(a*b)= log(a)+log(b)</li>
</ul>
<p><em>logits layer means the last neuron layer of neural network for classification task which produces raw prediction values.</em></p>
<p><em>Logits: numeric output of the last linear layer of a multi-class classification neural network. Before activation takes place.</em></p>
<p>Softmax function is <em>frequently appended to</em> the last layer of an image classification network such as cnn.</p>
<ul>
<li><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588105160/soft2_a3nsm6.png" alt=""></li>
</ul>
<h2 id="classical-ML-V-S-DL"><a href="#classical-ML-V-S-DL" class="headerlink" title="classical-ML V.S DL"></a>classical-ML V.S DL</h2><p><em>Ex: text classification</em></p>
<h3 id="classical-ML"><a href="#classical-ML" class="headerlink" title="classical ML:"></a>classical ML:</h3><ol>
<li>Map a text string to a vector representation <strong>x</strong>, using a set of <strong>hand-engineered</strong> features.</li>
<li>Learn a linear classifier with a softmax layer to compute the distribution.</li>
</ol>
<p><em>Design effort: feature engineering</em></p>
<h3 id="DL"><a href="#DL" class="headerlink" title="DL"></a>DL</h3><p>Jointly optimize the <em>feature representation</em> and <em>classification</em> using a DNN.</p>
<p><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588128439/ml-vs-dl_nel4rq.png" alt=""></p>
<p>DNN consists of two halves:</p>
<ol>
<li>top half: linear classifier, similar to classical ML.</li>
<li>The input vector of top half is <strong>not from hand-engineered features</strong>, but learned using the bottom half of the DNN.</li>
</ol>
<p><em>Design Effort: optimize DNN architectures for effective representation learning.</em></p>
<h2 id="Which-NN-neural-network-to-choose"><a href="#Which-NN-neural-network-to-choose" class="headerlink" title="Which NN(neural network) to choose?"></a>Which NN(neural network) to choose?</h2><p><strong>Depend on the type of linguistic structures that we hope to capture in the text.</strong></p>
<ol>
<li><p>Option 1: Word Embedding Layers</p>
<p>Map each word to a m-dimensional real-valued vector.</p>
</li>
<li><p>Option 2ï¼š Fully Connected Layers</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>[BASIC]Word Embedding</title>
    <url>/2020/04/30/BASIC-Word-Embedding/</url>
    <content><![CDATA[<h1 id="Word-Embedding-layers"><a href="#Word-Embedding-layers" class="headerlink" title="Word Embedding layers"></a>Word Embedding layers</h1><h2 id="Define-word-embedding"><a href="#Define-word-embedding" class="headerlink" title="Define word embedding"></a>Define word embedding</h2><p>Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.</p>
<p>Word embeddings are in fact a class of techniques where individual words are represented as real-valued vectors in a predefined vector space. Each word is mapped to one vector and the vector values are learned in a way that resembles a neural network, <strong>based on the usage of the words.</strong></p>
<p>Each word is represented as a <strong>one hot</strong> vector, whose dimensionality <em>n</em> is the size of a pre-defined voca<br>bulary. The vocabulary is often too large. Word embedding model is to map each one-hot vector to a m-dimensional real-valued vector. m ã€Š n. The number of features is much smaller than the size of the vocabulary.</p>
<h3 id="one-hot"><a href="#one-hot" class="headerlink" title="one-hot"></a>one-hot</h3><p>EX1: Suppose you have â€˜flowerâ€™ feature which can take values â€˜daffodilâ€™, â€˜lilyâ€™, and â€˜roseâ€™. One hot encoding converts â€˜flowerâ€™ feature to three features, â€˜is_daffodilâ€™, â€˜is_lilyâ€™, and â€˜is_roseâ€™ which all are binary.</p>
<p>EX2: <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588178728/one-hot_qa7mmr.png" alt=""></p>
<p>Word embeddng is one of the key breakthroughs of DL on challenging NLP.  </p>
<ol>
<li><strong>low-dimensinal vector</strong>: the majority of neural network toolkits do not play well with very high-dimensional, sparse vectors</li>
<li><strong>dense vector</strong>:  it is worthwhile to provide a representation that is able to capture these similarities on features.</li>
</ol>
<h2 id="Word-embedding-algorithms"><a href="#Word-embedding-algorithms" class="headerlink" title="Word embedding algorithms"></a>Word embedding algorithms</h2><p><strong>Word embedding methods are learning process.</strong></p>
<p>They learn a <em>real-valued vector representation</em> for a predefined fixed sized vocabulary <em>from a corpus of text</em>.</p>
<p>Two types of learning process:</p>
<ol>
<li>Joint with neural network model on some task.</li>
<li>Unsupervised process, using document statistics.</li>
</ol>
<p>Three ways to learn a word embedding:</p>
<p><strong>1.Embedding layer</strong></p>
<p>Itâ€™s a word embedding, which is learned jointly with a <em>neural network model</em> on a <em>specific</em> natural language processing task(ex: language modeling or document classification).</p>
<p>Itâ€™s <em>used</em> on the front end of a neural network and is fit in a supervised way using a Backpropagation algorithm.</p>
<p>It requires that document text be cleaned and prepared such that each word is one-hot encoded.</p>
<ul>
<li>disadvantage: It requires a lot of training data and can be slow</li>
<li>advantage: It will learn an embedding both targeted to the <em>specific text data</em> and the <em>NLP task</em>.</li>
</ul>
<p><strong>2. Word2Vec</strong></p>
<p>It is <strong>effient</strong>, good at capturing syntactic and semantic regularities, learns a <em>standalone</em> word embedding from a text corpus.</p>
<pre><code>low space and time complexity
more dimensions
much larger corpora of text </code></pre><p><strong>Ex: King - man + woman = Queen.</strong></p>
<p>â€“ Word2Vec involved analysis of the learned vectors and the exploration of vector math on the representations of words. </p>
<p><em>Two different models</em>:</p>
<ul>
<li><p>CBOW(continuous Bag-of-Words) model</p>
<p>  CBOW learns the embedding by predicting the current word based on its context.</p>
</li>
<li><p>Continuous Skip-Gram Model</p>
<p>  It learns by predicting the surrounding words given a current word.</p>
</li>
</ul>
<p><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588197753/word2vec_j3hnqr.png" alt=""></p>
<p><strong>Size of sliding winodw</strong><br>The context is defined by a window of neighboring words. This window is a configurable parameter of the model.</p>
<p>Large windows tend to produce more topical similarities, while smaller windows tend to produce more functional and syntactic similarities.</p>
<p><strong>3.GloVe: The Global Vectors for Word Representation</strong></p>
<p>It is an extension to the word2vec method for efficiently learning word vectors. GloVe is an approach to marry both the <em>global statistics of matrix factorization techniques</em> like LSA with the <em>local context-based learning</em> in word2vec.</p>
<ul>
<li>LSA(latent semantic analysis): Itâ€™s for analyzing relationships between a set of documents and the terms they contain by <em>producing a set of concepts related to the documents and terms</em>. LSA assumes that <em>words that are close in meaning will occur in similar pieces of text</em>. A matrix containing word counts per document (rows represent unique words and columns represent each document). Documents are then compared by taking the cosine of the angle between the two vectors (or the dot product between the normalizations of the two vectors) formed by any two columns. Values close to 1 represent very similar documents while values close to 0 represent very dissimilar documents</li>
</ul>
<p>Rather than using a window to define local context, <em>GloVe constructs an explicit word-context or word co-occurrence matrix using statistics across the whole text corpus.</em></p>
<p>GloVe performs well at word analogy, word similarity, and named entity recognition tasks.</p>
]]></content>
      <tags>
        <tag>BASIC</tag>
      </tags>
  </entry>
  <entry>
    <title>ç¢ç¢å¿µ-å‰é€”æœªåœ</title>
    <url>/2020/05/20/%E7%A2%8E%E7%A2%8E%E5%BF%B5-%E5%89%8D%E9%80%94%E6%9C%AA%E5%8D%9C/</url>
    <content><![CDATA[<h5 id="æˆ‘ä»¬èµ°å‡ºäººç”Ÿä¸­å‡ ä¹æ‰€æœ‰å…³é”®æ€§æ­¥éª¤æ—¶ï¼Œéƒ½æ˜¯åœ¨ä¸€ç§éš¾ä»¥è§‰å¯Ÿçš„æƒ…å†µä¸‹é¡ºåº”å†…å¿ƒçš„ç»“æœã€‚"><a href="#æˆ‘ä»¬èµ°å‡ºäººç”Ÿä¸­å‡ ä¹æ‰€æœ‰å…³é”®æ€§æ­¥éª¤æ—¶ï¼Œéƒ½æ˜¯åœ¨ä¸€ç§éš¾ä»¥è§‰å¯Ÿçš„æƒ…å†µä¸‹é¡ºåº”å†…å¿ƒçš„ç»“æœã€‚" class="headerlink" title="æˆ‘ä»¬èµ°å‡ºäººç”Ÿä¸­å‡ ä¹æ‰€æœ‰å…³é”®æ€§æ­¥éª¤æ—¶ï¼Œéƒ½æ˜¯åœ¨ä¸€ç§éš¾ä»¥è§‰å¯Ÿçš„æƒ…å†µä¸‹é¡ºåº”å†…å¿ƒçš„ç»“æœã€‚"></a>æˆ‘ä»¬èµ°å‡ºäººç”Ÿä¸­å‡ ä¹æ‰€æœ‰å…³é”®æ€§æ­¥éª¤æ—¶ï¼Œéƒ½æ˜¯åœ¨ä¸€ç§éš¾ä»¥è§‰å¯Ÿçš„æƒ…å†µä¸‹é¡ºåº”å†…å¿ƒçš„ç»“æœã€‚</h5><p>å›å›½ä¸€å‘¨å•¦ï¼Œåœ¨å¹¿å·é›†ä¸­éš”ç¦»ã€‚è™½è¯´æ˜¯ä¸€ä¸ªäººå¾…åœ¨æˆ¿é—´é‡Œé¢ä¸è®©å‡ºå»ï¼Œçœ‹èµ·æ¥æœ‰ç‚¹æƒ¨ï¼Œä½†æˆ‘ä¼¼ä¹å¹¶æ²¡æœ‰ä»€ä¹ˆéš¾å—çš„æ„Ÿè§‰ã€‚é…’åº—å·¥ä½œäººå‘˜éƒ½å¾ˆå‹å–„ï¼Œçˆ¸å¦ˆç»™çš„é’±ä¹Ÿè¶³å¤Ÿå¤šï¼Œæ¯å¤©ç‚¹çš„å¤–å–éƒ½å¾ˆå¥½åƒï¼ˆå¹¿å·å±…ç„¶å¯ä»¥é€šè¿‡å¤–å–ç‚¹åˆ°å–œèŒ¶ï¼ï¼ï¼ï¼‰ï¼Œæ‰‹ä¸Šä¹Ÿä¸€ç›´éƒ½æœ‰äº‹æƒ…åšã€‚è¿‡å»çš„ä¸€å‘¨é‡Œï¼Œå‰ä¸‰å››å¤©éƒ½åœ¨æ€¥ç€çœ‹Related Work,åç¯‡å·¦å³çš„å¯†å¯†éº»éº»çš„è‹±æ–‡è®ºæ–‡çœ‹çš„å¤´çš®å‘éº»å˜¤å˜¤å˜¤ï¼Œå¯èƒ½æ˜¯ç¬”è®°æœ¬çš„å±å¹•å¤ªå°äº†ä¸èˆ’æœå§~å› ä¸ºæ˜¯åšä¿¡æ¯æŠ½å–ï¼Œä¸å¿…è‡ªå·±æå‡ºç®—æ³•æ”¹è¿›æ¨¡å‹ä¹‹ç±»çš„ï¼Œæ‰€ä»¥è¿˜ç®—å¥½ä¸Šæ‰‹ï¼Œå­¦ä¹ éš¾åº¦ä¹Ÿä¸æ˜¯ç‰¹åˆ«å¤§ã€‚æ•´ç†æˆæ–‡æ¡£å‘ç»™è€å¸ˆåï¼Œè¢«å¤¸æ˜¯Very well-organizedï¼Œå“ˆå“ˆå“ˆæˆ‘å¿«ä¹äº†ã€‚</p>
<p>åé¢å‡ å¤©èŠ±äº†ä¸€å¤©å†™ä¸­åä¹æ•™å¯¼å¼•çš„ä½œä¸šï¼Œæˆ‘é€‰çš„é¢˜ç›®æ˜¯ä¸­åä¹æ•™åœ¨å½“ä»£çš„å¼˜æ‰¬è·¯å¾„ï¼Œä¸€ä¸å°å¿ƒå†™å‡ºäº†ä¸€ç¯‡ä¹ æ¦‚è¯¾æ–‡çš„æ„Ÿè§‰ï¼Œæœç„¶æ˜¯å¤šå¹´ä¸å†™æ–‡ç« ã€å†™ä½œèƒ½åŠ›é€€åŒ–åˆ°å°å­¦æ°´å¹³ã€‚å¸Œæœ›ä»¥åèƒ½æŠ½ç©ºå¤šå†™å†™åšæ–‡ï¼Œç»ƒç»ƒæ‰‹ä¹Ÿæ˜¯å¥½çš„ã€‚</p>
<p>è€ƒè™‘åˆ°ç¾å›½å—ç–«æƒ…çš„å½±å“ï¼Œæˆ‘å¼€å§‹è€ƒè™‘èµ·ä¿ç ”çš„äº‹æƒ…ã€‚ä¹‹å‰æƒ³ç€å»ç¾å›½ï¼Œå…¶å®æ˜¯æœ‰ä¿éšœçš„ã€‚å¦‚æœè¯»master,é‚£æ¯•ä¸šä¹‹åå¯ä»¥é«˜è–ªå·¥ä½œã€ä¹Ÿå¯ä»¥ç»§ç»­ç”³è¯·phdã€‚å¦‚æœè¯»phdï¼Œäº”å¹´è¯»å‡ºæ¥åˆæœ‰ç§‘ç ”å®åŠ›åˆæœ‰ä¸€å †æ–‡ç« å’Œäººè„‰ï¼Œä¸è®ºæ˜¯å·¥ä½œè¿˜æ˜¯å›å›½æ‹¿æ•™èŒéƒ½æ˜¯æå¥½çš„ã€‚ä½†ç–«æƒ…å½±å“ç¾å›½ç»æµï¼Œè¿™æ ·ä¸€æ¥è¯»å®Œmasterå¯èƒ½æ‰¾ä¸åˆ°å·¥ä½œã€éœ€è¦å›å›½996ï¼Œé‚£ä½•å¿…å‡ºå›½è¯»ä¸¤å¹´è€Œä¸ç•™åœ¨å›½å†…è¯»å‘¢ï¼Ÿ Phdçš„è¯é¢„è®¡æ˜å¹´ä¼šå¾ˆéš¾ç”³è¯·ï¼Œå¦‚æœè€å¸ˆæ²¡æœ‰fundingä¸æ‹›å­¦ç”Ÿï¼Œé‚£å°±æ²¡æœ‰phdå¯è¯»ã€‚å›½å†…ä¿ç ”çš„è¯ï¼Œäººå¤šå‘å°‘ï¼Œç«äº‰é‚£å«ä¸€ä¸ªæƒ¨çƒˆã€‚æŠ±ç€ä¹°å½©ç¥¨çš„å¿ƒæ€æŠ¥åäº†å‡ ä¸ªå¤ä»¤è¥ï¼Œæ„Ÿè°¢æ„¿æ„ä¸ºæˆ‘æ¨èçš„è¶…çº§æ— æ•Œå¥½çš„æ–‡è€å¸ˆå’Œé»„è€å¸ˆ~</p>
<p>å¶å°”è¿˜æ˜¯ä¼šæ€€å¿µè¾¾ç‰¹èŒ…æ–¯çš„è“å¤©ã€Teyenè€æ¿å®¶é—¨å£çš„Connecticut Riverã€è½»è½»é£˜è½é›ªèŠ±çš„Hanoverå°é•‡ã€‚æ›´æ€€å¿µåœ¨å®éªŒå®¤åºŸå¯å¿˜é£Ÿåˆå¿«ä¹çš„å¹²æ´»çš„è‡ªå·±å“ˆå“ˆå“ˆ</p>
<p>å…³äºè¯»ç ”çš„å»å‘é—®é¢˜ï¼Œæœ€è¿‘é—®äº†ä¸å°‘äººã€‚å‚åŠ å·¥ä½œæœ‰å‚åŠ å·¥ä½œçš„ä¹è¶£ï¼Œä¹Ÿæ²¡æœ‰æƒ³è±¡ä¸­çš„007å¼çš„è¾›è‹¦ï¼Œå·¥èµ„ä¹Ÿæ¯”æˆ‘å½¢è±¡ä¸­çš„é«˜å¾ˆå¤šï¼›å›½å†…è¯»ç ”ä¹Ÿæœ‰å›½å†…çš„å¥½å¤„ï¼Œå¦‚æœè·Ÿçš„æ˜¯æœ¬æ ¡æœ€å‰å®³çš„è€å¸ˆï¼Œé‚£ç¡•å£«æœŸé—´ä¹Ÿä¼šè¿‡å¾—å¾ˆå¥½ï¼Œè€å¸ˆä¼šæ”¯æŒä½ çš„æƒ³æ³•ï¼Œç»™äºˆå¾ˆå¤§çš„å¸®åŠ©ï¼›ä½†å¦‚æœå»å¤–æ ¡è¯»ç ”ï¼Œå°†é¢ä¸´å¯¼å¸ˆå¾ˆæ°´çš„é£é™©ï¼Œæœ¬æ ¡æœ¬ç§‘ç”Ÿä¸€ç›´ä»¥æ¥éƒ½æ˜¯è¯¥æ ¡ç¡•å£«çš„æœ€å¥½ç”Ÿæºï¼Œå¥½çš„è€å¸ˆçš„åé¢åŸºæœ¬ä¸Šéƒ½ä¼šåˆ†é…ç»™æœ¬æ ¡çš„å­¦ç”Ÿï¼Œå¤–æ ¡å­¦ç”Ÿè¿›å»æœ¬èº«å°±å¾ˆå›°éš¾ã€è¿›å»ä¹‹åèƒ½è·Ÿä¸€ä¸ªå¥½çš„è€å¸ˆå°±æ›´å›°éš¾ï¼Œæˆ‘è®¤ä¸ºå›½å†…å»å¤–æ ¡ä¿ç ”æ˜¯ä¸€åœºèµŒåšï¼Œä¸å¤ªæƒ³å†’è¿™ä¸ªé™©ã€‚å›½å†…åªæŠ¥æ¸…åŒ—çš„å¤ä»¤è¥ï¼Œèƒ½ä¸èƒ½å»éƒ½éšç¼˜ï¼›æš‘å‡çš„ä¸»è¦ç²¾åŠ›è¿˜æ˜¯æ”¾åœ¨å‡ºå›½çš„å‡†å¤‡æ–¹é¢ï¼šåšæš‘ç ”ï¼›è€ƒè¯­è¨€ã€‚æœ€åå¤§æ¦‚ç‡ä¼šæ˜¯è€è€å®å®å‡ºå›½~</p>
<p>è™½ç„¶ç–«æƒ…çš„åˆ°æ¥å¯¼è‡´æƒ…å†µéå¸¸å¤æ‚ï¼Œè®¡åˆ’èµ¶ä¸ä¸Šå˜åŒ–ï¼Œä½†æˆ‘ä¹Ÿä¹äºæ¥å—å˜å¹»è«æµ‹çš„æœªçŸ¥çš„æœªæ¥ã€å˜åŒ–æœªå°ä¸æ˜¯å¥½äº‹å‘¢ï¼Ÿ</p>
]]></content>
      <tags>
        <tag>LIFE</tag>
      </tags>
  </entry>
  <entry>
    <title>Survey-NLP-Health</title>
    <url>/2020/05/20/Survey-NLP-Health/</url>
    <content><![CDATA[<h2 id="å„ç¯‡æ–‡ç« çš„æ¦‚è¿°"><a href="#å„ç¯‡æ–‡ç« çš„æ¦‚è¿°" class="headerlink" title="å„ç¯‡æ–‡ç« çš„æ¦‚è¿°"></a>å„ç¯‡æ–‡ç« çš„æ¦‚è¿°</h2><h3 id="Large-scale-Analysis-of-Counseling-Conversations-An-Application-of-Natural-Language-Processing-to-Mental-Health"><a href="#Large-scale-Analysis-of-Counseling-Conversations-An-Application-of-Natural-Language-Processing-to-Mental-Health" class="headerlink" title="Large-scale Analysis of Counseling Conversations: An Application of Natural Language Processing to Mental Health"></a>Large-scale Analysis of Counseling Conversations: An Application of Natural Language Processing to Mental Health</h3><p>è‡ªç„¶è¯­è¨€å¤„ç†åœ¨å¿ƒç†å¥åº·é¢†åŸŸçš„ä¸€ä¸ªåº”ç”¨ï¼šåˆ†æå¤§è§„æ¨¡çš„å’¨è¯¢å¯¹è¯ã€‚</p>
<p><strong>ç ”ç©¶çš„å‡ºå‘ç‚¹ï¼š</strong></p>
<p>ç”±äºè¿‡å»ç¼ºä¹å¤§è§„æ¨¡çš„å¸¦æœ‰æ ‡è®°äº†çš„ç»“æœçš„å¯¹è¯æ•°æ®ï¼Œæˆ‘ä»¬ä¸€ç›´éƒ½æ²¡ææ¸…æ¥šåº”è¯¥å¦‚ä½•å¼•å¯¼æˆåŠŸçš„å’¨è¯¢å¯¹è¯ã€‚</p>
<p><strong>æˆ‘ä»¬çš„åŠªåŠ›</strong></p>
<p>æˆ‘ä»¬åœ¨ä»¥æ–‡å­—ä¸ºæ²Ÿé€šæ–¹å¼çš„å¯¹è¯æ•°æ®ä¸Šï¼Œåšäº†å¤§è§„æ¨¡çš„é‡åŒ–çš„ç ”ç©¶ã€‚é€šè¿‡è®¡ç®—æœºæ¥è¡¡é‡è¯­è¨€å­¦æ–¹é¢æ˜¯å¦‚ä½•å½±å“åˆ°å¯¹è¯ç»“æœçš„ã€‚</p>
<p><strong>Contribution</strong></p>
<ol>
<li>æ˜¯ç›®å‰ä¸ºæ­¢çš„æœ€å¤§è§„æ¨¡çš„å’¨è¯¢å¯¹è¯ç­–ç•¥æ–¹é¢çš„ç ”ç©¶</li>
<li>ç‰¹åˆ«çš„ï¼Œæˆ‘ä»¬æ³¨é‡åˆ†æå’¨è¯¢å¸ˆï¼Œè€Œä¸æ˜¯åˆ†æç—…äººã€‚å› ä¸ºæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯é€šç”¨çš„å¯¹è¯ç­–ç•¥ç ”ç©¶ã€è€Œä¸æ˜¯å…·ä½“æŸä¸€ä¸ªè¯é¢˜ã€‚</li>
<li>æˆ‘ä»¬æ‰¾åˆ°äº†åˆ‡å®å¯è¡Œçš„å¯¹è¯ç­–ç•¥ï¼š: Adaptability; Dealing with ambiguity; Creativity; Making progress; Change in perspective.</li>
<li>æˆ‘ä»¬è¯æ˜äº†å¯¹è¯çš„ç»“æœæ˜¯å¯ä»¥é€šè¿‡æˆ‘ä»¬å‘ç°çš„é‚£äº›ç­–ç•¥ç‰¹å¾æ¥é¢„æµ‹çš„ã€‚</li>
</ol>
<p><strong>è¯„ä»·</strong></p>
<p>æˆ‘æŒºå–œæ¬¢è¿™ç¯‡æ–‡ç« çš„ï¼Œå¸Œæœ›æˆ‘ä»¬ä¹Ÿå¯ä»¥åšå‡ºç±»ä¼¼çš„ä¸œè¥¿ã€‚æ„Ÿè§‰è¡Œæ–‡éå¸¸è‡ªç„¶ï¼Œé¡ºç•…ã€‚</p>
<h3 id="The-Channel-Matters-Self-disclosure-Reciprocity-and-Social-Support-in-Online-Cancer-Support-Groups"><a href="#The-Channel-Matters-Self-disclosure-Reciprocity-and-Social-Support-in-Online-Cancer-Support-Groups" class="headerlink" title="The Channel Matters: Self-disclosure, Reciprocity and Social Support in Online Cancer Support Groups"></a>The Channel Matters: Self-disclosure, Reciprocity and Social Support in Online Cancer Support Groups</h3><p>channelå½±å“äº†åœ¨çº¿ç™Œç—‡æ”¯æŒå°ç»„ä¸­äººä»¬å‘æœ‹å‹åœˆåæ§½å’Œä¸ºä»–äººæä¾›æ”¯æŒé¼“åŠ±çš„æ–¹å¼</p>
<p><strong>ç ”ç©¶çš„å‡ºå‘ç‚¹</strong> </p>
<p>æˆ‘ä»¬æƒ³çŸ¥é“ ä¹‹å‰çš„å¯¹äº äººä»¬åœ¨é€šç”¨ç½‘ç«™ï¼ˆfacebook)ä¸Šé¢ä½¿ç”¨ä¸åŒçš„channelè¿›è¡Œè‡ªæˆ‘è¡¨éœ²ï¼ˆå‘æœ‹å‹åœˆï¼‰çš„æ–¹å¼çš„ çš„ç ”ç©¶æ˜¯ä¸æ˜¯é€‚ç”¨äºåœ¨çº¿å¥åº·æ”¯æŒå°ç»„ä¸­ã€‚</p>
<p><strong>æˆ‘ä»¬æ£€æµ‹äº†è¿™äº›æ–¹é¢</strong> </p>
<ol>
<li>åœ¨åœ¨çº¿ç™Œç—‡æ”¯æŒå°ç»„ä¸­ï¼Œäººä»¬ä½¿ç”¨å…¬å¼€çš„channelå’Œç§å¯†çš„channelå‘æœ‹å‹åœˆçš„ä¸åŒæ–¹å¼ã€‚</li>
<li>channelæ˜¯å¦‚ä½•å¹³è¡¡å¥½å‘æœ‹å‹åœˆåæ§½å’Œæä¾›æ”¯æŒå¸®åŠ©è¿™ä¸¤ä¸ªæ–¹é¢çš„ã€‚</li>
</ol>
<h3 id="Causal-Factors-of-Effective-Psychosocial-Outcomes-in-Online-Mental-Health-Communities"><a href="#Causal-Factors-of-Effective-Psychosocial-Outcomes-in-Online-Mental-Health-Communities" class="headerlink" title="Causal Factors of Effective Psychosocial Outcomes in Online Mental Health Communities"></a>Causal Factors of Effective Psychosocial Outcomes in Online Mental Health Communities</h3><p>åœ¨çº¿å¿ƒç†å¥åº·ç¤¾åŒºä¸­ï¼Œäº§ç”Ÿæœ‰æ•ˆçš„ç¤¾äº¤å¿ƒç†å­¦æ•ˆæœçš„ä¸€äº›åŸå› </p>
<p><strong>ç ”ç©¶çš„å‡ºå‘ç‚¹</strong></p>
<p>æˆ‘ä»¬å¥½å¥‡ï¼šåŒä¼´é—´çš„æ”¯æŒï¼ˆpeer supportï¼‰ä¸­çš„å“ªäº›å› ç´ é€ æˆäº†æœ‰æ•ˆçš„ç¤¾äº¤å¯¹è¯æ•ˆæœï¼Ÿ</p>
<p><strong>Contribution</strong></p>
<p>æˆ‘ä»¬ä½¿ç”¨ä¸ªä¾‹å¯¹ç…§æ³•ï¼ˆcase-control)æ¥ç ”ç©¶æ˜¯ä»€ä¹ˆå› ç´ å¯¼è‡´äº†æœ‰æ•ˆçš„æ”¯æŒã€‚<br>ä¸ªä¾‹å¯¹ç…§æ³•æ¥è‡ªäºæµè¡Œç—…å­¦ï¼Œå®ƒçš„å¥½å¤„æ˜¯ï¼šä¸åƒæ­£å› æœæ¨è®ºæ³•ï¼ˆ forward causal inference methodsï¼‰éœ€è¦æŠŠå˜é‡äºŒè¿›åˆ¶åŒ–ï¼Œæˆ‘ä»¬ä¿ç•™åŸå€¼ã€‚è¿™ä¸ªæ–¹æ³•å¯¹äºâ‘ ç»“æœæ˜¯æ˜ç¡®å®šä¹‰çš„â‘¡å› ç´ æ˜¯è¿ç»­å˜é‡çš„åˆ†ææ˜¯å¾ˆæœ‰æ•ˆçš„ã€‚<br>æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…å¯ä»¥åŒæ—¶ç ”ç©¶å¤šä¸ªå› ç´ çš„å½±å“ï¼Œè¿˜å¯ä»¥ç ”ç©¶å•ä¸ªå› ç´ åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæœ‰å½±å“ã€‚</p>
<h3 id="Trouble-on-the-Horizon-Forecasting-the-Derailment-of-Online-Conversations-as-they-Develop"><a href="#Trouble-on-the-Horizon-Forecasting-the-Derailment-of-Online-Conversations-as-they-Develop" class="headerlink" title="Trouble on the Horizon: Forecasting the Derailment of Online Conversations as they Develop"></a>Trouble on the Horizon: Forecasting the Derailment of Online Conversations as they Develop</h3><p>åœ¨å¯¹è¯ä¸­çš„å†²çªå‡ºç°ä¹‹å‰å°±é¢„æµ‹åˆ°å³å°†äº§ç”Ÿçš„å†²çª</p>
<p><strong>ç ”ç©¶çš„å‡ºå‘ç‚¹</strong></p>
<p>åœ¨çº¿çš„èŠå¤©ä¸­ï¼Œå¤§å®¶å¯èƒ½èŠç€èŠç€å°±å‘ç”Ÿäº†å†²çªã€äº‰åµã€æ”»å‡»å¯¹æ–¹ã€‚æœ€è¿‘åˆ«äººçš„ç ”ç©¶ä¸»è¦åœ¨æ£€æµ‹å•å¥è¯ä¸­çš„å¼•èµ·ç¤¾äº¤å†²çª(antisocial bahavior)ï¼Œåœ¨èŠå¤©ç»“æŸä¹‹åæ‰æ¥åˆ†æã€‚æˆ‘ä»¬æƒ³è¦åœ¨å¯¹è¯ä¸­å‡ºç°å†²çªä¹‹å‰åŠæ—¶é¢„æµ‹åˆ°å³å°†å‡ºç°å†²çªã€‚<br>è¦å®ç°é¢„æµ‹æœ‰å‡ ä¸ªéš¾é¢˜ï¼š</p>
<ol>
<li>å¯¹è¯æ˜¯åŠ¨æ€çš„ï¼Œäº§ç”Ÿä»€ä¹ˆç»“æœæ˜¯å–å†³äºåç»­åŒæ–¹çš„äº¤æµã€‚ä¹‹å‰çš„è§£å†³æ–¹å¼æ˜¯ï¼šä¸»è¦ä¾èµ–äºæ‰‹å·¥åˆ¶ä½œçš„featureæ¥æ‰¾åˆ°å†²çªã€‚ä¹Ÿæœ‰äººç”¨neural attentionçš„æ–¹å¼æ¥è§£å†³ã€‚</li>
<li>å¯¹è¯çš„é•¿åº¦ä¸å®šï¼Œéœ€è¦é¢„æµ‹çš„å¯èƒ½å‡ºç°çš„å†²çªå¯èƒ½éšæ—¶å‡ºç°ã€‚ä¹‹å‰çš„å·¥ä½œæ˜¯ï¼šâ‘ é¢„æµ‹å‘ç”Ÿå†²çªçš„æ—¶é—´ï¼Œåœ¨é‚£ä¸ªæ—¶é—´åˆ°çš„æ—¶å€™æ¥æ£€æŸ¥ï¼›â‘¡ä»å›ºå®šå¤§å°çš„çª—å£ä¸­æŠ½å–ç‰¹å¾ã€‚ï¼ˆåæ§½ç‚¹ï¼šwindow-size?)</li>
</ol>
<p><strong>Contribution</strong></p>
<ol>
<li>ä¸€ä¸ªæ¨¡å‹ï¼šå¯ä»¥åœ¨å¯¹è¯å‘ç”Ÿçš„è¿‡ç¨‹ä¸­å®ç°é¢„æµ‹ã€‚</li>
<li>é€šè¿‡å®æ—¶åˆ†æå„ä¸ªè¯­å¥ä»¥åŠä»–ä»¬çš„å…³ç³»ï¼Œå…‹æœäº†é‚£å‡ ä¸ªéš¾é¢˜ã€‚</li>
<li><strong><em>åœ¨å¯¹è¯é¢„æµ‹é¢†åŸŸç¬¬ä¸€ä¸ªä½¿ç”¨pre-train-then-fine-tuneæ–¹æ³•çš„ã€‚</em></strong></li>
</ol>
<h3 id="Seekers-Providers-Welcomers-and-Storytellers-Modeling-Social-Roles-in-Online-Health-Communities"><a href="#Seekers-Providers-Welcomers-and-Storytellers-Modeling-Social-Roles-in-Online-Health-Communities" class="headerlink" title="Seekers, Providers, Welcomers, and Storytellers: Modeling Social Roles in Online Health Communities"></a>Seekers, Providers, Welcomers, and Storytellers: Modeling Social Roles in Online Health Communities</h3><p>ç»™åœ¨çº¿å¥åº·ç¤¾åŒºä¸­çš„äººè¿›è¡Œç¤¾ä¼šè§’è‰²å»ºæ¨¡ï¼Œåˆ†ä¸ºå¯»æ±‚å¸®åŠ©è€…ï¼Œæä¾›å¸®åŠ©è€…ï¼Œæ¬¢è¿æ–°äººè€…ï¼Œè®²æ•…äº‹çš„äººã€‚</p>
<p><strong>Contribution</strong></p>
<p>æˆ‘ä»¬ä»ç™Œç—‡äº’åŠ©ç¤¾åŒºä¸­ï¼Œä»¥ç”¨æˆ·çš„è¡Œä¸ºæ¨¡å¼ä¸ºä¾æ®ï¼Œå»ºäº†11ä¸ªç‰¹å®šåŠŸèƒ½çš„è§’è‰²æ¨¡å¼ã€‚<br>æˆ‘ä»¬è¿˜ç ”ç©¶äº†è§’è‰²çš„åŠ¨æ€å˜åŒ–ï¼ŒåŒ…æ‹¬ï¼šåœ¨ç”¨æˆ·ä½¿ç”¨è¿™ä¸ªç¤¾åŒºæœŸé—´ï¼Œç”¨æˆ·çš„è§’è‰²æ˜¯å¦‚ä½•æ”¹å˜çš„ï¼Ÿ å¦‚ä½•æ ¹æ®è§’è‰²æ¥é¢„æµ‹ç”¨æˆ·æ˜¯å¦ä¼šé•¿æœŸå‚ä¸åˆ°è¿™ä¸ªç¤¾åŒºä¸­ï¼Ÿ<br>æˆ‘ä»¬å‘ç°ï¼Œç”¨æˆ·é¢‘ç¹çš„æ”¹å˜è‡ªå·±çš„è§’è‰²ï¼Œä»æ±‚åŠ©è€…åˆ°æä¾›å¸®åŠ©è€…ã€‚æ•´ä¸ªç¤¾åŒºçš„è§’è‰²åˆ†å¸ƒè¿˜æ˜¯ç¨³å®šçš„ã€‚<br>æ—©æœŸå°±å½¢æˆç‰¹å®šè§’è‰²çš„äººåœ¨ç¤¾åŒºä¸­å‚ä¸æ—¶é—´ä¼šæ›´é•¿ã€‚</p>
<h3 id="Linguistic-Markers-Indicating-Therapeutic-Outcomes-of-Social-Media-Disclosures-of-Schizophrenia"><a href="#Linguistic-Markers-Indicating-Therapeutic-Outcomes-of-Social-Media-Disclosures-of-Schizophrenia" class="headerlink" title="Linguistic Markers Indicating Therapeutic Outcomes of Social Media Disclosures of Schizophrenia"></a>Linguistic Markers Indicating Therapeutic Outcomes of Social Media Disclosures of Schizophrenia</h3><p>ç²¾ç¥åˆ†è£‚ç—‡</p>
<p><strong>ç ”ç©¶çš„å‡ºå‘ç‚¹</strong><br>è¶Šæ¥è¶Šå¤šçš„äººå¼€å§‹åœ¨ç¤¾äº¤åª’ä½“ç½‘ç«™ä¸Šå€¾è¯‰è‡ªå·±çš„ä¸å¼€å¿ƒã€‚æˆ‘ä»¬æƒ³çŸ¥é“ï¼š</p>
<ol>
<li>åœ¨å‘æœ‹å‹åœˆå‰åï¼Œè¡Œä¸ºæœ‰ä»€ä¹ˆå˜åŒ–ï¼Ÿ</li>
<li>è¿™äº›è¡Œä¸ºå˜åŒ–ä¸­ï¼ŒåŒ…æ‹¬åˆ©äºæ²»ç–—çš„â€opening upâ€å—ï¼Ÿ</li>
</ol>
<p><strong>Contribution</strong></p>
<ol>
<li>ç”¨é‡åŒ–çš„æ–¹å¼æ¥æ‰¾åˆ°disclosureå‰åçš„æ—¶é—´é˜¶æ®µã€‚</li>
<li>ç”¨ä¸€ç³»åˆ—è¯­è¨€å­¦çš„æŒ‡æ ‡æ¥æè¿°disclosureå‰åçš„è¡Œä¸ºå˜åŒ–</li>
<li>æˆ‘ä»¬æ‰¾åˆ°äº†disclosureä¹‹åäº§ç”Ÿç–—æ•ˆçš„å› ç´ ï¼šimproved readability and coherence in language, future orientation, lower self preoccupation, and reduced discussion of symptoms and stigma perceptions</li>
</ol>
<p><strong>è¯„è®º</strong><br>è¿™ç¯‡æ–‡ç« æˆ‘ä¹Ÿå¾ˆå–œæ¬¢ã€‚è¡Œæ–‡é¡ºç•…ï¼Œé€»è¾‘å¾ˆè‡ªç„¶ã€‚</p>
<h3 id="What-Makes-a-Good-Counselor-Learning-to-Distinguish-between-High-quality-and-Low-quality-Counseling-Conversations"><a href="#What-Makes-a-Good-Counselor-Learning-to-Distinguish-between-High-quality-and-Low-quality-Counseling-Conversations" class="headerlink" title="What Makes a Good Counselor? Learning to Distinguish between High-quality and Low-quality Counseling Conversations"></a>What Makes a Good Counselor? Learning to Distinguish between High-quality and Low-quality Counseling Conversations</h3><p>é€šè¿‡åˆ†æå¥½å’¨è¯¢å¸ˆå’Œåå’¨è¯¢å¸ˆçš„ä¸åŒç‚¹ï¼Œä»è€Œæ‰¾åˆ°å¦‚ä½•æˆä¸ºä¸€ä¸ªå¥½çš„å’¨è¯¢å¸ˆçš„æ–¹æ³•</p>
<p><strong>Contribution</strong></p>
<ol>
<li>ä½¿ç”¨æ¥è‡ªpublic sources çš„noisyçš„å’¨è¯¢æ•°æ®ï¼Œæ¥åˆ†æå’¨è¯¢è´¨é‡ã€‚ï¼ˆå®ç”¨ï¼Œç‚¹èµğŸ‘ï¼‰</li>
<li>é€šè¿‡åˆ†æå¯¹è¯çš„å„ä¸ªæ–¹é¢ï¼ˆ turn-by-turn interaction, the sentiment expressed during the interaction, linguistic alignment, and salient topics)ï¼Œä»è€Œæ‰¾åˆ°äº†é«˜è´¨é‡å’¨è¯¢çš„æ¨¡å¼ã€‚</li>
<li>é€šè¿‡æˆ‘ä»¬åˆ†æä¸­æ‰¾åˆ°çš„ç‰¹å¾å’Œæ ‡å‡†N-GRAMç‰¹å¾ï¼Œæå‡äº†å’¨è¯¢è´¨é‡åˆ†ç±»å™¨çš„ç²¾åº¦ã€‚</li>
</ol>
<h3 id="Moments-of-Change-Analyzing-Peer-Based-Cognitive-Support-in-Online-Mental-Health-Forums"><a href="#Moments-of-Change-Analyzing-Peer-Based-Cognitive-Support-in-Online-Mental-Health-Forums" class="headerlink" title="Moments of Change: Analyzing Peer-Based Cognitive Support in Online Mental Health Forums"></a>Moments of Change: Analyzing Peer-Based Cognitive Support in Online Mental Health Forums</h3><p><strong>ç ”ç©¶çš„å‡ºå‘ç‚¹</strong><br>é‡å¡‘ä¸ç†æ€§çš„è®¤çŸ¥å¯ä»¥ç»™å¿ƒç†ç–¾ç—…æ‚£è€…å¸¦æ¥ç§¯æçš„è®¤çŸ¥çš„æ”¹å˜ã€‚æˆ‘ä»¬æƒ³çŸ¥é“ï¼šåœ¨è·Ÿæœ‹å‹çš„å¯¹è¯ä¸­ï¼ˆpeer to peer)ï¼Œè¿™äº›è®¤çŸ¥çš„æ”¹å˜æ˜¯å¦‚ä½•å‘ç”Ÿçš„ã€‚</p>
<p><strong>æˆ‘ä»¬çš„åŠªåŠ›</strong></p>
<ol>
<li>å®šä¹‰äº†â€œa moment of changeâ€.å¯¹äºä¸€ä¸ªæ‚£è€…æ›¾ç»è¡¨ç¤ºè´Ÿé¢æƒ…ç»ªçš„è¯é¢˜ï¼Œåªè¦æ‚£è€…è¡¨è¾¾äº†ç§¯æçš„æƒ…ç»ªï¼Œé‚£æˆ‘ä»¬å°±ç§°ä¹‹ä¸ºâ€a moment of changeâ€</li>
<li>æå‡ºäº†ä¸€ä¸ªæ¨¡å‹ï¼Œå¯ä»¥é¢„æµ‹ä¸€ä¸ªå¯¹è¯æˆ–è€…ä¸€ä¸ªæœ‹å‹åœˆï¼ˆpost)ä¸­æ˜¯å¦æœ‰å‘ç”Ÿâ€œa moment of changeâ€</li>
<li>æˆ‘ä»¬æå‡ºçš„SentiTopicæ¨¡å‹å¯ä»¥æ˜¾å¼çš„è¿½è¸ªæ¯ä¸ªpostä¸­çš„è¯é¢˜å’Œæƒ…æ„Ÿã€‚æ®æ­¤æˆ‘ä»¬çŸ¥é“é‡å¡‘è®¤çŸ¥æ˜¯å¦‚ä½•å‘ç”Ÿçš„ã€‚</li>
</ol>
<p><strong>è¯„ä»·</strong></p>
<p>è¿™ç¯‡æˆ‘ä¹Ÿå–œæ¬¢233ï¼Œå®æ—¶çš„è¿½è¸ªè¯é¢˜å¾ˆæœ‰è¶£</p>
<h3 id="Finding-Your-Voice-The-Linguistic-Development-of-Mental-Health-Counselors"><a href="#Finding-Your-Voice-The-Linguistic-Development-of-Mental-Health-Counselors" class="headerlink" title="Finding Your Voice: The Linguistic Development of Mental Health Counselors"></a>Finding Your Voice: The Linguistic Development of Mental Health Counselors</h3><p>å’¨è¯¢å¸ˆéšç€ç»éªŒçš„ç´¯ç§¯ åœ¨è¯­è¨€æ–¹é¢çš„è¿›æ­¥</p>
<p><strong>ç ”ç©¶çš„é—®é¢˜</strong></p>
<p>éšç€ç»éªŒçš„ç´¯ç§¯ï¼Œå’¨è¯¢å¸ˆåœ¨å“ªç§ç¨‹åº¦ä¸Šæ”¹å˜ä»–ä»¬çš„linguistic behaviorï¼Ÿè¿™ä¸ªæ”¹å˜çš„åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ</p>
<p><strong>æˆ‘ä»¬çš„å·¥ä½œ</strong></p>
<ol>
<li>åœ¨ä¸¤ä¸ªç»´åº¦é‡åŒ–äº†å’¨è¯¢å¸ˆçš„å˜åŒ–ï¼šå’¨è¯¢å¸ˆè‡ªå·±ï¼›å’¨è¯¢å¸ˆä¹‹é—´<strong>Contribution</strong>ç”±æ­¤æˆ‘ä»¬æ˜¯ç¬¬ä¸€ä¸ªè¯æ˜äº†å’¨è¯¢å¸ˆç¡®å®ä¼šéšç€ç»éªŒçš„ç´¯ç§¯è€Œè¿›æ­¥çš„ã€‚</li>
<li>è®¡ç®—äº†å’¨è¯¢å¸ˆçš„æ”¹å˜çš„é€Ÿç‡</li>
<li>æ‰¾åˆ°äº†ä¸€äº›æœ‰ç”¨çš„å¯ä»¥å¯¼è‡´æ˜æ˜¾çš„å’¨è¯¢å¸ˆæ”¹å˜çš„åŸå› ã€‚</li>
</ol>
<p><strong>è¯„ä»·</strong><br>å–œæ¬¢ï¼Œâ€œç¬¬ä¸€ä¸ªxxxâ€æ€»ç»™äººä¸€ç§å¾ˆæœ‰ç”¨çš„æ„Ÿè§‰</p>
<h3 id="The-role-of-conversation-in-health-care-interventions-enabling-sensemaking-and-learning"><a href="#The-role-of-conversation-in-health-care-interventions-enabling-sensemaking-and-learning" class="headerlink" title="The role of conversation in health care interventions: enabling sensemaking and learning"></a>The role of conversation in health care interventions: enabling sensemaking and learning</h3><p>è¿™æ˜¯ä¸€ç¯‡çº¯ç²¹çš„å¿ƒç†å­¦ç ”ç©¶ï¼Œåˆ†æäº†å¯¹è¯åœ¨ä¿å¥ä¸­çš„ä½œç”¨ï¼šenabling sensemaking and learningã€‚å¹¶åˆ†æäº†åŸå› <br>Sensemakingå°±æ˜¯é‡åˆ°æœŸæœ›ä¹‹å¤–çš„æƒ…å†µæ—¶ï¼Œå¦‚ä½•ç”¨ä»¥å‰çš„çŸ¥è¯†å»è§£å†³æœªçŸ¥çš„é—®é¢˜ã€‚<br>Learningæ˜¯é€šè¿‡ä¸å¤–ç•Œäº¤æ¢ä¿¡æ¯ï¼Œä»è€Œè°ƒæ•´è‡ªå·±çš„è§‚ç‚¹å’Œç­–ç•¥ã€‚</p>
<h2 id="å››ä¸ªé—®é¢˜çš„å›ç­”"><a href="#å››ä¸ªé—®é¢˜çš„å›ç­”" class="headerlink" title="å››ä¸ªé—®é¢˜çš„å›ç­”"></a>å››ä¸ªé—®é¢˜çš„å›ç­”</h2><h3 id="How-do-we-predict-the-quality-of-therapy-conversations-given-the-survey-like-self-reported-satisfaction-score-among-different-mental-health-conditions"><a href="#How-do-we-predict-the-quality-of-therapy-conversations-given-the-survey-like-self-reported-satisfaction-score-among-different-mental-health-conditions" class="headerlink" title="How do we predict the quality of therapy conversations given the survey-like self-reported satisfaction score among different mental health conditions?"></a>How do we predict the quality of therapy conversations given the survey-like self-reported satisfaction score among different mental health conditions?</h3><p>æ ¹æ®Survey-likeçš„è¡¨ï¼Œå¦‚ä½•é¢„æµ‹å¯¹è¯çš„æ²»ç–—è´¨é‡ï¼Ÿ</p>
<p>ç›®å‰æ²¡æœ‰äººåšï¼šex.5ä¸ªé—®é¢˜ï¼Œæ¯ä¸ªé—®é¢˜è¯„åˆ†1-10.<br>ç›®å‰åšçš„äº‹æƒ…ï¼š</p>
<ol>
<li>æ ¹æ®è¯­è¨€å­¦æ–¹é¢åˆ†æå’¨è¯¢è´¨é‡</li>
<li>çœ‹æœ‰æ²¡æœ‰a moment of change</li>
<li>é—®å’¨è¯¢è€…æ˜¯å¦æ„Ÿè§‰å—åˆ°äº†å¸®åŠ©ã€‚ï¼ˆæˆ‘è®¤ä¸ºä¸æé—®â€œæ˜¯å¦â€ï¼Œè€Œæ˜¯è¯¢é—®â€œç¨‹åº¦â€ä¼šå¥½ä¸€äº›ã€‚</li>
</ol>
<h3 id="Given-the-limited-number-of-self-reported-score-how-do-we-build-a-classification-model-that-can-utilize-the-information"><a href="#Given-the-limited-number-of-self-reported-score-how-do-we-build-a-classification-model-that-can-utilize-the-information" class="headerlink" title="Given the limited number of self-reported score, how do we build a classification model that can utilize the information?"></a>Given the limited number of self-reported score, how do we build a classification model that can utilize the information?</h3><p>ç»™å®šæœ‰é™æ•°é‡çš„question 1ä¸­çš„é—®å·ï¼Œæˆ‘ä»¬å¦‚ä½•æ„å»ºåˆ†ç±»æ¨¡å‹ï¼Ÿ</p>
<ol>
<li>logitic regressionæ¨¡å‹æ¥é¢„æµ‹ã€‚ï¼ˆå¤§è§„æ¨¡æ•°æ®ï¼‰</li>
<li>pre-train-then-fine-tuneï¼ˆå°è§„æ¨¡æ•°æ®ï¼‰</li>
<li>SVM ï¼ˆsupport vector machine classifiers)(å°è§„æ¨¡)</li>
</ol>
<h3 id="How-do-we-discover-the-linguistic-features-that-can-improve-the-quality-of-conversations"><a href="#How-do-we-discover-the-linguistic-features-that-can-improve-the-quality-of-conversations" class="headerlink" title="How do we discover the linguistic features that can improve the quality of conversations?"></a>How do we discover the linguistic features that can improve the quality of conversations?</h3><p>å¦‚ä½•æ‰¾åˆ°æå‡å¯¹è¯è´¨é‡çš„è¯­è¨€å­¦ç‰¹å¾ï¼Ÿ</p>
<p>åšçš„äººå¤ªå¤šäº†ï¼Œä¸æ˜¯æˆ‘ä»¬çš„contribution</p>
<h3 id="Are-linguistic-features-differ-among-different-mental-health-conditions-If-so-how-should-we-detect-such-differences"><a href="#Are-linguistic-features-differ-among-different-mental-health-conditions-If-so-how-should-we-detect-such-differences" class="headerlink" title="Are linguistic features differ among different mental health conditions? If so, how should we detect such differences?"></a>Are linguistic features differ among different mental health conditions? If so, how should we detect such differences?</h3><p>ä¸åŒçš„å¿ƒç†ç–¾ç—…ä¹‹é—´çš„è¯­è¨€å­¦ç‰¹å¾ç›¸åŒå—ï¼Ÿä¸åŒçš„è¯ï¼Œæˆ‘ä»¬å¦‚ä½•æ‰¾åˆ°è¿™äº›ä¸åŒï¼Ÿ</p>
<p>ç›®å‰æ²¡æœ‰äººä¸“é—¨ç ”ç©¶è¿™ä¸ªé—®é¢˜ï¼Œåªæ˜¯é›¶é›¶æ•£æ•£çš„ç ”ç©¶æŸä¸ªæ–¹é¢ï¼Œæ¯”å¦‚ç™Œç—‡ã€ç²¾ç¥åˆ†è£‚ç—‡ã€‚<br>æˆ‘ä»¬å¯èƒ½çš„contribution:é€šè¿‡æŸ¥æ‰¾åˆ«äººåšè¿‡çš„ + æ¢ç©¶åˆ«äººæ²¡åšè¿‡çš„ ï¼Œåšä¸€ä¸ªå¿ƒç†ç–¾ç—…çš„æ±‡æ€»å·¥ä½œã€‚</p>
<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><ol>
<li>æƒ³çŸ¥é“æ›´å¤šæœ‰å…³é¡¹ç›®çš„å†…å®¹ï¼šæ•°æ®é›†åŒ…å«å“ªäº›ä¿¡æ¯ã€ä»€ä¹ˆæ ¼å¼ï¼›æˆ‘ä»¬è¦åšä»€ä¹ˆäº‹æƒ…ï¼›æˆ‘ä»¬çš„Contributionåœ¨å“ªï¼Ÿ<br>ç›®å‰æˆ‘å·²çŸ¥çš„å†…å®¹æ˜¯ï¼šæœ‰åŒ»ç”Ÿå’Œç—…äººä¹‹é—´çš„1W-2Wçš„æ•°æ®é›†ï¼Œæ˜¯å¯¹è¯ã€‚</li>
<li>æ—¶é—´å®‰æ’ï¼šæš‘å‡é™¤äº†è€ƒGTä¹‹å¤–ï¼Œå¯èƒ½ä¼šå‚åŠ ä¸€ä¸ªå¤ä»¤è¥ï¼Œå†æ²¡äº†ã€‚æ—¶é—´åº”è¯¥è¶³å¤Ÿï¼Œå¸Œæœ›åˆ¶å®šæ—¶é—´è®¡åˆ’ã€‚<br>è°ƒç ”å·¥ä½œ<br>æ–¹æ³•çš„æ€»ä½“å®‰æ’<br>åˆ†éƒ¨å¼€å§‹æ‰§è¡Œ<br>å†™è®ºæ–‡<br>ä¿®æ”¹è®ºæ–‡ </li>
<li>è¯¢é—®è€æ¿å¯¹äºç–«æƒ…è¿‡åç•™å­¦ç”³è¯·çš„çœ‹æ³•ï¼šç–«æƒ…å¯¹Phdæ‹›ç”Ÿçš„å½±å“ï¼›å¯¹Masterå·¥ä½œçš„å½±å“ã€‚</li>
</ol>
]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>week1-health</title>
    <url>/2020/05/21/week1-health/</url>
    <content><![CDATA[<h3 id="TASK-1W-2Wå¯»æ‰¾research-topic"><a href="#TASK-1W-2Wå¯»æ‰¾research-topic" class="headerlink" title="TASK:1W-2Wå¯»æ‰¾research topic"></a>TASK:1W-2Wå¯»æ‰¾research topic</h3><p>åœ¨ç»™å®šçš„æ•°æ®é›†ä¸‹å¯»æ‰¾ä»»ä½•å¯èƒ½çš„research topic.</p>
<h4 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h4><p>å¿ƒç†ç–¾ç—…ï¼šæŠ‘éƒç—‡ï¼Œç„¦èºç—‡ã€‚<br>ä¸“ä¸šçš„çº¿ä¸ŠæŠ‘éƒç—‡èŠå¤©å¹³å°ï¼Œç”¨æˆ·åˆšè¿›å…¥ç½‘ç«™çš„æ—¶å€™ä¼šå¡«ä¸€äº›é—®é¢˜ï¼Œä»è€Œè¢«matchä¸€äº›å’¨è¯¢å¸ˆã€‚ç±»ä¼¼äºå¾®ä¿¡ä¸€æ ·ï¼Œæ‚£è€…å¯ä»¥é€‰æ‹©åŒæ—¶è·Ÿå¤šä¸ªäººèŠå¤©ã€ä¹Ÿå¯ä»¥ä¸€ç›´å°±è·ŸæŸä¸€ä¸ªäººèŠå¤©ã€‚èŠå¤©çš„è¿‡ç¨‹ä¸­ï¼Œæ‚£è€…å¯ä»¥like the message(ç±»ä¼¼äºslack)ï¼Œç»“æŸä¹‹åæ‚£è€…ä¼šå¡«ä¸€ä¸ªevaluation formï¼Œè¯´è‡ªå·±æ˜¯å¦æ»¡æ„ã€‚<br><em>ç‰¹åˆ«çš„ï¼Œæ‚£è€…å¯ä»¥é€‰æ‹©ä¸€ç›´è·ŸæŸä¸ªäººèŠå¤©</em> ï¼Œ è¿™æ˜¯å¼‚äºä»¥å¾€ä»»ä½•ç ”ç©¶çš„ã€‚æˆ‘ä»¬å¯ä»¥ç”±æ­¤æ·»åŠ ä¸€ä¸ªæ–°çš„Measure:æ‚£è€…ä¸‹ä¸€æ¬¡æ˜¯å¦ç»§ç»­è·ŸæŸä¸ªå’¨è¯¢å¸ˆèŠå¤©ã€‚éšç€èŠå¤©çš„è¿›è¡Œï¼Œä»–ä»¬çš„è¯é¢˜ã€æƒ…æ„Ÿéƒ½å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ï¼Œå¯èƒ½ä¼šæ›´åŠ çš„äº²å¯†ã€‚</p>
<h4 id="inspirationï¼šèŠçš„è¶Šå¤šè¶Šäº²å¯†å—ï¼Ÿ"><a href="#inspirationï¼šèŠçš„è¶Šå¤šè¶Šäº²å¯†å—ï¼Ÿ" class="headerlink" title="inspirationï¼šèŠçš„è¶Šå¤šè¶Šäº²å¯†å—ï¼Ÿ"></a>inspirationï¼šèŠçš„è¶Šå¤šè¶Šäº²å¯†å—ï¼Ÿ</h4><p>åšä¸€ä¸ªæ¨¡å‹ï¼Œåˆ†æäº²å¯†ç¨‹åº¦è·ŸèŠå¤©æ¬¡æ•°ã€èŠå¤©æ—¶é•¿çš„å…³ç³»ï¼›åˆ†æè¯é¢˜ã€æƒ…æ„Ÿçš„å˜åŒ–ï¼šæ˜¯å¦åœ¨linguistic featureä¸Šé¢æœ‰å˜åŒ–ï¼Œä¾‹å¦‚ï¼š</p>
<ol>
<li><p>Successful counselors are better at <strong>adapting</strong> to the conversation<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1590033524/02_q7rtvp.png" alt=""><br>åˆ†ææ–¹å¼1ï¼šâ‘  Look for language differences between positive and negative conversations<br>â‘¡ Observe how this distance changes over time<br>åˆ†ææ–¹å¼2ï¼štopical congruence &amp; linguistic style accommodation</p>
</li>
<li><p>More successful counselors react more strongly to <strong>ambiguous</strong> situations than less successful counselors.<br>åˆ†ææ–¹å¼ï¼š Compare how more-successful and less-successful counselors react given nearly identical situations</p>
</li>
<li><p>More successful counselors use less common/<strong>templated</strong> responses<br>åˆ†ææ–¹å¼1ï¼šCount the number of similar responses in TF-IDF space for the counselor reaction<br>åˆ†ææ–¹å¼2ï¼šâ‘ Average distance (or diversity) among the responses received(higher, better)<br>â‘¡To inspect top keywords in responses received to check if they are generic.</p>
</li>
<li><p>More successful counselors <strong>coordinate less</strong> than less successful ones<br>åˆ†ææ–¹å¼ï¼šâ‘  Divide a conversation into 5 stages with unsupervised model.<br>â‘¡ Compute the average duration in messages of each stage.<br>â‘¢ Explore the reason for step2 by analyzing linguistic coordination.<br>åˆ†ææ–¹å¼2ï¼š<br>Linguistic Style Matching(LSM) and  linguistic Style Coordination(LSC) method</p>
</li>
<li><p>Counselor actively induce <strong>perspective change: time, self, sentiment</strong><br>åˆ†ææ–¹å¼ï¼šTime: the relative amount of words in the LIWC past, present, and future categories<br>Self: relative amount of first person singular pronouns (I, me, mine) versus third person singular/plural pronouns (she, her, him / they, their), again using LIWC.<br>Sentiment: the relative fraction of positive words using the LIWC PosEmo and NegEmo sentiment lexicons.</p>
</li>
<li><p>Longer responses and lower <strong>repeatability</strong> of words are more likely to help psychosocial improvement.<br>åˆ†ææ–¹å¼ï¼šAverage length of response &amp; Average number of unique words per response</p>
</li>
<li><p>Emotionality: greater <strong>positivity</strong> is associated with effective.<br>åˆ†ææ–¹å¼ï¼šæ— </p>
</li>
<li><p>Credibility of the Responders: responses from members who are more <strong>active on the platform</strong> seem to be typically more effective.<br>åˆ†ææ–¹å¼ï¼š respondersâ€™ tenure (number of days on the platform) (no difference)<br>interactivity<br>number of posts(no difference)<br>the frequency of posting behavior (posts per day)</p>
</li>
<li><p><strong>Average words per turnï¼ˆ for counselor)ï¼Œword ratioï¼Œsentiment change</strong> of counselor<br>åˆ†ææ–¹å¼ï¼š Analyze turn-by-turn interaction by calculating each speakerâ€™s average word per turn and word ratio between client and counselor.<br>Divide each session into 5 stagesï¼Œeach stage has similar numbers of turns. We calculate average number of words per stage</p>
</li>
<li><p>relation between <strong>topic</strong> and counseling quality<br>åˆ†ææ–¹å¼ï¼šâ‘  meaning extraction method(MEM)ï¼Œ to get resulting word list.<br>â‘¡ Generate counselor and client matrices containing binary vectors indicating the use of each word by a specific speaker<br>â‘¢ Run a Principal Component Analysis (PCA), followed by varimax rotation on each document matrix to find clus- ters of co-occurring nouns. This process results in 10 and 8 components (topics) for counselors and clients respectively</p>
</li>
<li><p>linguistic diversity<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1590033397/01_q0krwu.png" alt=""><br>åˆ†ææ–¹å¼ï¼šSTEP 1: Design a general framework aimed at capturing the degree of linguistic diversity.<br>STEP 2: Instantiate this framework in the counseling domain.<br>STEP 3: Estimate the relation between the linguistic diversity of counselors and their effectiveness in engendering positive outcomes.<br>STEP 4: Use the resulting high level linguistic characterization to analyze the evolution. (MAIN FOCUS)</p>
</li>
<li><p>ç‰¹åˆ«çš„ï¼Œç”±äºæ•°æ®é›†çš„ç‰¹åˆ«ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸€ä¸ªç‰¹å¾ï¼šä¸‹æ¬¡æ˜¯å¦è¿˜ç»§ç»­è·ŸåŒä¸€ä¸ªåŒ»ç”ŸèŠå¤©ã€‚</p>
</li>
</ol>
<h4 id="inspirationï¼šéšç€èŠå¤©è¶Šæ¥è¶Šå¤šï¼Œä»–ä»¬çš„è¯é¢˜æ˜¯å¦å˜åŒ–ï¼Ÿæƒ…æ„Ÿæ˜¯å¦å˜åŒ–ï¼Ÿä¸Šè¿°çš„è¯­è¨€featureæ˜¯å¦å˜åŒ–ï¼Ÿ"><a href="#inspirationï¼šéšç€èŠå¤©è¶Šæ¥è¶Šå¤šï¼Œä»–ä»¬çš„è¯é¢˜æ˜¯å¦å˜åŒ–ï¼Ÿæƒ…æ„Ÿæ˜¯å¦å˜åŒ–ï¼Ÿä¸Šè¿°çš„è¯­è¨€featureæ˜¯å¦å˜åŒ–ï¼Ÿ" class="headerlink" title="inspirationï¼šéšç€èŠå¤©è¶Šæ¥è¶Šå¤šï¼Œä»–ä»¬çš„è¯é¢˜æ˜¯å¦å˜åŒ–ï¼Ÿæƒ…æ„Ÿæ˜¯å¦å˜åŒ–ï¼Ÿä¸Šè¿°çš„è¯­è¨€featureæ˜¯å¦å˜åŒ–ï¼Ÿ"></a>inspirationï¼šéšç€èŠå¤©è¶Šæ¥è¶Šå¤šï¼Œä»–ä»¬çš„è¯é¢˜æ˜¯å¦å˜åŒ–ï¼Ÿæƒ…æ„Ÿæ˜¯å¦å˜åŒ–ï¼Ÿä¸Šè¿°çš„è¯­è¨€featureæ˜¯å¦å˜åŒ–ï¼Ÿ</h4><h4 id="inspiration-æˆåŠŸçš„counseloråˆ°åº•æ˜¯æ€ä¹ˆå®‰æ…°äººçš„-ä»–ä»¬æœ‰å“ªäº›strategy-æˆ‘ä»¬èƒ½å¦å‘ç°æ›´å¤šçš„strategy"><a href="#inspiration-æˆåŠŸçš„counseloråˆ°åº•æ˜¯æ€ä¹ˆå®‰æ…°äººçš„-ä»–ä»¬æœ‰å“ªäº›strategy-æˆ‘ä»¬èƒ½å¦å‘ç°æ›´å¤šçš„strategy" class="headerlink" title="inspiration: æˆåŠŸçš„counseloråˆ°åº•æ˜¯æ€ä¹ˆå®‰æ…°äººçš„? ä»–ä»¬æœ‰å“ªäº›strategy? æˆ‘ä»¬èƒ½å¦å‘ç°æ›´å¤šçš„strategy?"></a>inspiration: æˆåŠŸçš„counseloråˆ°åº•æ˜¯æ€ä¹ˆå®‰æ…°äººçš„? ä»–ä»¬æœ‰å“ªäº›strategy? æˆ‘ä»¬èƒ½å¦å‘ç°æ›´å¤šçš„strategy?</h4><p>åŸ¹è®­å’¨è¯¢å¸ˆåº”è¯¥åŸ¹è®­å“ªäº›æ–¹é¢ï¼Ÿ</p>
<p>éœ€è¦è¡¥ä¸€äº›å¿ƒç†å­¦çš„çŸ¥è¯†</p>
<h4 id="åˆ†æç—…äººéšç€å¾…åœ¨å¹³å°çš„æ—¶é—´ï¼Œé€‰æ‹©çš„èŠå¤©çš„äººçš„å˜åŒ–æƒ…å†µã€‚ä¸ºä»€ä¹ˆä¼šä¸€ç›´è·ŸæŸäººèŠä¸‹å»"><a href="#åˆ†æç—…äººéšç€å¾…åœ¨å¹³å°çš„æ—¶é—´ï¼Œé€‰æ‹©çš„èŠå¤©çš„äººçš„å˜åŒ–æƒ…å†µã€‚ä¸ºä»€ä¹ˆä¼šä¸€ç›´è·ŸæŸäººèŠä¸‹å»" class="headerlink" title="åˆ†æç—…äººéšç€å¾…åœ¨å¹³å°çš„æ—¶é—´ï¼Œé€‰æ‹©çš„èŠå¤©çš„äººçš„å˜åŒ–æƒ…å†µã€‚ä¸ºä»€ä¹ˆä¼šä¸€ç›´è·ŸæŸäººèŠä¸‹å»"></a>åˆ†æç—…äººéšç€å¾…åœ¨å¹³å°çš„æ—¶é—´ï¼Œé€‰æ‹©çš„èŠå¤©çš„äººçš„å˜åŒ–æƒ…å†µã€‚ä¸ºä»€ä¹ˆä¼šä¸€ç›´è·ŸæŸäººèŠä¸‹å»</h4><h4 id="å·²å…¬å¼€ä¸”å…è®¸ä½¿ç”¨çš„æ•°æ®é›†æœ‰å“ªäº›ï¼Ÿ"><a href="#å·²å…¬å¼€ä¸”å…è®¸ä½¿ç”¨çš„æ•°æ®é›†æœ‰å“ªäº›ï¼Ÿ" class="headerlink" title="å·²å…¬å¼€ä¸”å…è®¸ä½¿ç”¨çš„æ•°æ®é›†æœ‰å“ªäº›ï¼Ÿ"></a>å·²å…¬å¼€ä¸”å…è®¸ä½¿ç”¨çš„æ•°æ®é›†æœ‰å“ªäº›ï¼Ÿ</h4><p>RADDIT?</p>
]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>ä¿ç ”åçš„ç”Ÿæ´»</title>
    <url>/2020/10/27/%E4%BF%9D%E7%A0%94%E5%90%8E%E7%9A%84%E7%94%9F%E6%B4%BB/</url>
    <content><![CDATA[<h5 id="å¯¹ç”Ÿæ´»åšç§ç§è®¾ç½®æ˜¯äººç‰¹æœ‰çš„å“æ€§ã€‚ä¸å…‰æ˜¯è®¾ç½®åŠ¨ç‰©ï¼Œä¹Ÿè®¾ç½®è‡ªå·±ã€‚æˆ‘ä»¬çŸ¥é“ï¼Œåœ¨å¤å¸Œè…Šæœ‰ä¸ªæ–¯å·´è¾¾ï¼Œé‚£é‡Œçš„ç”Ÿæ´»è¢«è®¾ç½®å¾—äº†æ— ç”Ÿè¶£ï¼Œå…¶ç›®çš„å°±æ˜¯è¦ä½¿ç”·äººæˆä¸ºäº¡å‘½æˆ˜å£«ï¼Œä½¿å¥³äººæˆä¸ºç”Ÿè‚²æœºå™¨ï¼Œå‰è€…åƒæ–—é¸¡ï¼Œåè€…åƒæ¯çŒªã€‚è¿™ä¸¤ç±»åŠ¨ç‰©æ˜¯å¾ˆç‰¹åˆ«çš„ï¼Œä½†æˆ‘ä»¥ä¸ºï¼Œå®ƒä»¬è‚¯å®šä¸å–œæ¬¢è‡ªå·±çš„ç”Ÿæ´»ã€‚ä½†ä¸å–œæ¬¢åˆèƒ½æ€ä¹ˆæ ·ï¼Ÿäººä¹Ÿå¥½ï¼ŒåŠ¨ç‰©ä¹Ÿç½¢ï¼Œéƒ½å¾ˆéš¾æ”¹å˜è‡ªå·±çš„å‘½è¿ã€‚-â€”â€”â€”â€”ç‹å°æ³¢-ã€Šä¸€åªç‰¹ç«‹ç‹¬è¡Œçš„çŒªã€‹"><a href="#å¯¹ç”Ÿæ´»åšç§ç§è®¾ç½®æ˜¯äººç‰¹æœ‰çš„å“æ€§ã€‚ä¸å…‰æ˜¯è®¾ç½®åŠ¨ç‰©ï¼Œä¹Ÿè®¾ç½®è‡ªå·±ã€‚æˆ‘ä»¬çŸ¥é“ï¼Œåœ¨å¤å¸Œè…Šæœ‰ä¸ªæ–¯å·´è¾¾ï¼Œé‚£é‡Œçš„ç”Ÿæ´»è¢«è®¾ç½®å¾—äº†æ— ç”Ÿè¶£ï¼Œå…¶ç›®çš„å°±æ˜¯è¦ä½¿ç”·äººæˆä¸ºäº¡å‘½æˆ˜å£«ï¼Œä½¿å¥³äººæˆä¸ºç”Ÿè‚²æœºå™¨ï¼Œå‰è€…åƒæ–—é¸¡ï¼Œåè€…åƒæ¯çŒªã€‚è¿™ä¸¤ç±»åŠ¨ç‰©æ˜¯å¾ˆç‰¹åˆ«çš„ï¼Œä½†æˆ‘ä»¥ä¸ºï¼Œå®ƒä»¬è‚¯å®šä¸å–œæ¬¢è‡ªå·±çš„ç”Ÿæ´»ã€‚ä½†ä¸å–œæ¬¢åˆèƒ½æ€ä¹ˆæ ·ï¼Ÿäººä¹Ÿå¥½ï¼ŒåŠ¨ç‰©ä¹Ÿç½¢ï¼Œéƒ½å¾ˆéš¾æ”¹å˜è‡ªå·±çš„å‘½è¿ã€‚-â€”â€”â€”â€”ç‹å°æ³¢-ã€Šä¸€åªç‰¹ç«‹ç‹¬è¡Œçš„çŒªã€‹" class="headerlink" title="å¯¹ç”Ÿæ´»åšç§ç§è®¾ç½®æ˜¯äººç‰¹æœ‰çš„å“æ€§ã€‚ä¸å…‰æ˜¯è®¾ç½®åŠ¨ç‰©ï¼Œä¹Ÿè®¾ç½®è‡ªå·±ã€‚æˆ‘ä»¬çŸ¥é“ï¼Œåœ¨å¤å¸Œè…Šæœ‰ä¸ªæ–¯å·´è¾¾ï¼Œé‚£é‡Œçš„ç”Ÿæ´»è¢«è®¾ç½®å¾—äº†æ— ç”Ÿè¶£ï¼Œå…¶ç›®çš„å°±æ˜¯è¦ä½¿ç”·äººæˆä¸ºäº¡å‘½æˆ˜å£«ï¼Œä½¿å¥³äººæˆä¸ºç”Ÿè‚²æœºå™¨ï¼Œå‰è€…åƒæ–—é¸¡ï¼Œåè€…åƒæ¯çŒªã€‚è¿™ä¸¤ç±»åŠ¨ç‰©æ˜¯å¾ˆç‰¹åˆ«çš„ï¼Œä½†æˆ‘ä»¥ä¸ºï¼Œå®ƒä»¬è‚¯å®šä¸å–œæ¬¢è‡ªå·±çš„ç”Ÿæ´»ã€‚ä½†ä¸å–œæ¬¢åˆèƒ½æ€ä¹ˆæ ·ï¼Ÿäººä¹Ÿå¥½ï¼ŒåŠ¨ç‰©ä¹Ÿç½¢ï¼Œéƒ½å¾ˆéš¾æ”¹å˜è‡ªå·±çš„å‘½è¿ã€‚ â€”â€”â€”â€”ç‹å°æ³¢ ã€Šä¸€åªç‰¹ç«‹ç‹¬è¡Œçš„çŒªã€‹"></a>å¯¹ç”Ÿæ´»åšç§ç§è®¾ç½®æ˜¯äººç‰¹æœ‰çš„å“æ€§ã€‚ä¸å…‰æ˜¯è®¾ç½®åŠ¨ç‰©ï¼Œä¹Ÿè®¾ç½®è‡ªå·±ã€‚æˆ‘ä»¬çŸ¥é“ï¼Œåœ¨å¤å¸Œè…Šæœ‰ä¸ªæ–¯å·´è¾¾ï¼Œé‚£é‡Œçš„ç”Ÿæ´»è¢«è®¾ç½®å¾—äº†æ— ç”Ÿè¶£ï¼Œå…¶ç›®çš„å°±æ˜¯è¦ä½¿ç”·äººæˆä¸ºäº¡å‘½æˆ˜å£«ï¼Œä½¿å¥³äººæˆä¸ºç”Ÿè‚²æœºå™¨ï¼Œå‰è€…åƒæ–—é¸¡ï¼Œåè€…åƒæ¯çŒªã€‚è¿™ä¸¤ç±»åŠ¨ç‰©æ˜¯å¾ˆç‰¹åˆ«çš„ï¼Œä½†æˆ‘ä»¥ä¸ºï¼Œå®ƒä»¬è‚¯å®šä¸å–œæ¬¢è‡ªå·±çš„ç”Ÿæ´»ã€‚ä½†ä¸å–œæ¬¢åˆèƒ½æ€ä¹ˆæ ·ï¼Ÿäººä¹Ÿå¥½ï¼ŒåŠ¨ç‰©ä¹Ÿç½¢ï¼Œéƒ½å¾ˆéš¾æ”¹å˜è‡ªå·±çš„å‘½è¿ã€‚ â€”â€”â€”â€”ç‹å°æ³¢ ã€Šä¸€åªç‰¹ç«‹ç‹¬è¡Œçš„çŒªã€‹</h5><p>è·ç¦»ä¸Šä¸€æ¬¡æ›´æ–°åšå®¢å·²ç»å¿«äº”ä¸ªæœˆå•¦ã€‚è¿™äº”ä¸ªæœˆå‘ç”Ÿäº†è®¸è®¸å¤šå¤šçš„æ„æƒ³ä¸åˆ°çš„äº‹æƒ…ï¼Œæœ‰å¿«ä¹çš„æƒŠå–œçš„ã€ä¹Ÿæœ‰æ‚²ä¼¤çš„å§”å±ˆçš„ã€‚ä»Šæ—¥æ„Ÿå†’è¯·äº†ç—…å‡åœ¨å®¶ä¼‘æ¯ï¼Œé¡ºä¾¿å›å‘³ä¸€ä¸‹è¿™äº”ä¸ªæœˆä»¥æ¥çš„å–œæ€’å“€ä¹ï¼Œä»¥æ­¤åšæ–‡ä½œæµæ°´è´¦ã€‚å†™å®Œå›çœ‹è§‰å¾—è¿™ç¯‡åšå®¢å†™å¾—å®åœ¨ä¸å¥½ï¼Œè¿˜æœ›å„è·¯å¤§ç¥å¤šå¤šæŒ‡å¯¼ä¸€ä¸‹ï¼</p>
<h3 id="äº”æœˆÂ·éš”ç¦»"><a href="#äº”æœˆÂ·éš”ç¦»" class="headerlink" title="äº”æœˆÂ·éš”ç¦»"></a>äº”æœˆÂ·éš”ç¦»</h3><p><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1603802357/IMG_7570_20200920-223800_lklvkp.jpg" alt=""><br>äº”æœˆåå·ä¹‹å‰æˆ‘åœ¨Hanoverå°é•‡è¿‡ç€æ‚ é—²çš„å…»è€ç”Ÿæ´»ï¼šå¯’ç ”å·²ç»ç»“æŸï¼Œå°ä¼™ä¼´ä»¬å…¨éƒ½å·²ç»ç¦»å¼€ï¼Œå‰©ä¸‹å¯æ€œå¼±å°åˆæ— åŠ©ç­‰æœºç¥¨çš„æœ¬äººç•™å®ˆhanoverï¼Œç­‰å¾…å›å›½é‚£ä¸€å¤©çš„åˆ°æ¥ã€‚</p>
<p><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1603802406/IMG_8199_20200529-225733_snjrcl.jpg" alt=""><br>åœ¨å¹¿å·éš”ç¦»äº†åå››å¤©åï¼Œå›åˆ°å®¶é‡Œåˆè¢«ç¤¾åŒºè¦æ±‚è‡ªè§‰å±…å®¶éš”ç¦»åå››å¤©ï¼Œäºæ˜¯æ•´ä¸ªäº”æœˆå’Œå…­æœˆåˆå‡ ä¹éƒ½åœ¨éš”ç¦»ä¸­åº¦è¿‡äº†ã€‚ç°åœ¨å›æƒ³èµ·æ¥ï¼Œåœ¨å¹¿å·éš”ç¦»çš„é‚£æ®µæ—¥å­è¿˜æ˜¯éå¸¸çš„èˆ’æœçš„ï¼šçƒ­æƒ…çš„å·¥ä½œäººå‘˜è·‘ä¸Šè·‘ä¸‹çš„ç»™å¤§å®¶é€å¤–å–ï¼Œæ¸©æŸ”çš„æŠ¤å£«å°å§å§å°å“¥å“¥æ¯å¤©ä¸Šé—¨æŸ¥ä¸¤æ¬¡ä½“æ¸©ï¼Œéš”ç¦»ç»“æŸçš„æ—¶å€™éš”ç¦»é…’åº—è¿˜ç»™æ¯ä¸ªäººé€äº†â€œç¦â€çš„çº¢åº•æ¯›ç¬”å­—ç•™ä½œçºªå¿µã€‚åœ¨æ­¤å†æ¬¡æ„Ÿè°¢å¹¿å·ç•ªç¦ºåŒºçš„å®œå¿…æ€é…’åº—ï¼</p>
<h3 id="å…­æœˆÂ·æš‘ç ”"><a href="#å…­æœˆÂ·æš‘ç ”" class="headerlink" title="å…­æœˆÂ·æš‘ç ”"></a>å…­æœˆÂ·æš‘ç ”</h3><p>è¿™æ˜¯ä¸€æ®µéš¾å¿˜åˆéš¾å—çš„ç»å†ï¼Œå¤§æ¦‚å°±æ˜¯è·Ÿç€ç¾å›½æŸè‘—åé«˜æ ¡çš„raising starä¸€æ ·çš„ä¸€ä¸ªAPï¼Œç„¶åå…«å­—ä¸åˆé—¹çš„ä¸æ¬¢è€Œæ•£çš„äº‹æƒ…ï¼Œåœ¨æ­¤ç•¥å»ä¸€ä¸‡ä¸ªå­—ã€‚</p>
<h3 id="ä¸ƒæœˆÂ·ä¿ç ”"><a href="#ä¸ƒæœˆÂ·ä¿ç ”" class="headerlink" title="ä¸ƒæœˆÂ·ä¿ç ”"></a>ä¸ƒæœˆÂ·ä¿ç ”</h3><p>çœ‹ç€å›½é™…å½¢åŠ¿è¶Šæ¥è¶Šæ¶åŒ–ï¼Œä»¥åŠçˆ¶æ¯çš„æ‹…å¿ƒï¼Œæˆ‘é€‰æ‹©äº†ä¿ç ”ã€‚æµ·æŠ•äº†ä¸€æ³¢å­¦æ ¡ï¼šæ¸…ååŒ—å¤§å¤æ—¦ä¸Šäº¤ä¸­ç§‘å¤§ä¸­ç§‘é™¢æ¸¯ä¸­æ–‡ã€‚ä¸­å¥–äº†æ¸¯ä¸­æ–‡ã€ä¸­ç§‘å¤§ã€ä¸­ç§‘é™¢å’Œæ¸…åã€‚å½“æ—¶é¦™æ¸¯è¿˜æ²¡å‡ºå›½å®‰æ³•ï¼Œæ‹…å¿ƒå±€åŠ¿ä¸ç¨³å®šå°±æ²¡å»ã€‚æ¸…åçš„å¤ä»¤è¥åœ¨ä¸­ç§‘å¤§å’Œä¸­ç§‘é™¢çš„å‰é¢ï¼Œæ¸…åé¢è¯•å®Œä¹‹åè‡ªæˆ‘æ„Ÿè§‰è‰¯å¥½ï¼Œæ‰€ä»¥å°±æ²¡æœ‰ç»§ç»­å‚åŠ åé¢çš„ä¸¤ä¸ªå­¦æ ¡çš„æ´»åŠ¨äº†ã€‚</p>
<p>è™½ç„¶åé¢çš„å½•å–è¿‡ç¨‹éå¸¸çš„æ›²æŠ˜ï¼Œè®©æˆ‘ä¸€åº¦éå¸¸åæ‚”å½“åˆä¸ºä»€ä¹ˆæ²¡å¤šæ‹¿å‡ ä¸ªå­¦æ ¡çš„offerã€‚ä»Šå¹´ç”±äºç–«æƒ…çš„å½±å“ï¼Œæ•™è‚²éƒ¨åˆ†å‘ç ”ç©¶ç”Ÿåé¢çš„æ—¥æœŸæ¨è¿Ÿäº†å‡ ä¹ä¸€ä¸ªæœˆï¼Œå› æ­¤æˆ‘ä»¬å­¦æ ¡çš„ä¿ç ”èµ„æ ¼è¯æ˜ä¹Ÿè¿Ÿè¿Ÿæ²¡æœ‰å‘æ”¾ï¼Œä½†æ˜¯æ¸…åå¤§å­¦ä¾æ—§å‚¬ç€è¦æ±‚æˆ‘ä»¬å‡ºå…·ä¿ç ”èµ„æ ¼è¯æ˜æˆ–è€…å¼ºæœ‰åŠ›çš„è¾…åŠ©ææ–™ï¼Œç”±äºæœ¬äººå®åœ¨æ˜¯èœï¼Œä»¥ä¸Šä¸‰ä¸ªæœºæ„çš„æ—¶é—´å®‰æ’å†²çªç»™æˆ‘é€ æˆäº†å¾ˆå¤§çš„éº»çƒ¦ï¼Œå†æ¬¡æ„Ÿè°¢å¸®åŠ©æˆ‘çš„å„ä½è€å¸ˆå’Œç»™æˆ‘èˆ’ç¼“å‹åŠ›çš„å„ä½æœ‹å‹ã€‚</p>
<h3 id="å…«æœˆÂ·æ‰‹æœ¯"><a href="#å…«æœˆÂ·æ‰‹æœ¯" class="headerlink" title="å…«æœˆÂ·æ‰‹æœ¯"></a>å…«æœˆÂ·æ‰‹æœ¯</h3><p>åŠ¨äº†ä¸ªå°æ‰‹æœ¯ï¼Œä½é™¢äº†å‡ å¤©ã€‚ æœ‰äº†å®ä¹ çš„å¿µå¤´ï¼Œåœ¨educativeä¸Šåˆ·äº†ä¸€äº›ç®—æ³•é¢˜ã€‚åˆ·çš„æ˜¯grokking the coding interviewçš„é¢˜ç›®ï¼Œæˆ‘å¾ˆå–œæ¬¢è¿™ä¸ªè¯¾ç¨‹ï¼Œæ·±å…¥æµ…å‡ºï¼ŒæŠŠç®—æ³•é¢˜çš„å¥—è·¯åˆ†ä¸ºå‡ å¤§ç±»å‹ï¼Œæ¯ä¸ªç±»å‹éƒ½å…ˆä»ç®€å•çš„ä¾‹å­å¼€å§‹è®²æ€æƒ³ï¼Œç„¶åå†æ…¢æ…¢ä¸¾ä¸€åä¸‰ï¼Œç»™äººä¸€ç§æ— ç—›åˆ·é¢˜çš„ç¾å¥½ä½“éªŒã€‚<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1603803523/%E6%8D%95%E8%8E%B7_nzyop8.png" alt=""></p>
<h3 id="ä¹æœˆÂ·é‡è¿”æ ¡å›­"><a href="#ä¹æœˆÂ·é‡è¿”æ ¡å›­" class="headerlink" title="ä¹æœˆÂ·é‡è¿”æ ¡å›­"></a>ä¹æœˆÂ·é‡è¿”æ ¡å›­</h3><p>å¹´åˆä¸€æœˆç¦»å¼€æ­¦æ±‰å»ç¾å›½çš„æ—¶å€™ï¼Œæ­¦æ±‰æµ·é²œå¸‚åœºå°±å·²ç»çˆ†å‡ºæ–°é—»è¯´æœ‰ä¸æ˜ä¼ æŸ“ç—…äº†ï¼Œå› æ­¤æˆ‘è¿˜åœ¨å®¿èˆä¹°äº†ä¸¤å¤§åŒ…çš„å£ç½©ï¼Œè™½ç„¶æˆ‘ä¹Ÿæ‡’å¾—æˆ´ï¼Œç–«æƒ…æœŸé—´é€ç»™å®¿ç®¡é˜¿å§¨äº†ã€‚åˆšåˆ°ç¾å›½ä¸ä¹…æ­¦æ±‰å°±å°åŸäº†ï¼Œå†æ¬¡å›åˆ°æ ¡å›­å·²ç»æ˜¯ä¹æœˆï¼Œè¿™æ˜¯æˆ‘æ²¡æœ‰é¢„æ–™åˆ°çš„ã€‚</p>
<p>ä¹æœˆä¸»è¦åœ¨æŠ˜è…¾ä¿ç ”æ‰‹ç»­çš„äº‹æƒ…ï¼Œè¿™ä¸ªè¿‡ç¨‹æå…¶ç—›è‹¦ï¼Œå¥½åœ¨æœ€åé¡ºåˆ©çš„ä¿äº†ç ”ã€‚ä¹æœˆè¿˜è¿‡äº†ä¸€æ¬¡å›æƒ³èµ·æ¥è¿˜æ˜¯éå¸¸å¼€å¿ƒçš„ç”Ÿæ—¥ã€‚<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1603803753/DF753D32318538769EEE485E29DFAAEF_ar1zra.jpg" alt=""></p>
<h3 id="åæœˆÂ·å®ä¹ "><a href="#åæœˆÂ·å®ä¹ " class="headerlink" title="åæœˆÂ·å®ä¹ "></a>åæœˆÂ·å®ä¹ </h3><p>æŠ•äº†ä¸‰å®¶å…¬å¸ï¼Œå»äº†å›å¤æœ€å¿«çš„é‚£ä¸€å®¶ï¼ˆå¯¹ï¼Œå°±æ˜¯Intel)ã€‚è¿˜æœ‰ä¸€å®¶æ„¿æ„è¦æˆ‘çš„ç»„æ˜¯åšæ¸¸æˆçš„ï¼Œä¸å¤ªæ„Ÿå…´è¶£å°±æ²¡å»ã€‚è¿˜æœ‰ä¸€å®¶å›å¤çš„å®åœ¨å¤ªæ…¢ï¼Œåæœˆä¸­æ—¬æ‰æ‰“ç”µè¯æ¥ç¬”è¯•(â•¬â–”çš¿â–”)å‡¸</p>
<p>åæœˆåå››å·ï¼Œç»ˆäºå°˜åŸƒè½åœ°æ”¶åˆ°äº†æ¸…åå¤§å­¦çš„é¢„å½•å–é€šçŸ¥ã€‚è¯´ä¸ä¸Šå¤šä¹ˆå¼€å¿ƒï¼Œä¹Ÿè¯´ä¸ä¸Šå¤šä¹ˆéš¾å—ã€‚ä¸æ˜¯å¾ˆå¼€å¿ƒæ˜¯å› ä¸ºåŸè®¡åˆ’å‡ºå›½è¯»ä¹¦ï¼Œæ°å¥½å¹´åˆåœ¨Dartmouthåº¦è¿‡äº†æ„‰å¿«çš„å››ä¸ªæœˆï¼Œå»å®Œä¸€è¶Ÿç¾å›½ä¹‹åæ›´åŠ æ†§æ†¬åœ¨é‚£é‡Œåº¦è¿‡ä¸€æ®µå­¦ä¹ çš„æ—¶å…‰äº†ï¼Œæœ€åæ²¡èƒ½å»æˆï¼Œæœ‰ä¸€ç§æ›¾ç»æ²§æµ·éš¾ä¸ºæ°´çš„æ„Ÿè§‰ã€‚ä½†ä¹Ÿä¸æ˜¯å¾ˆéš¾å—ï¼Œç ”ç©¶ç”Ÿçš„å¯¼å¸ˆå‡ºäº†åçš„å¥½ï¼Œå¸ˆå…„å¸ˆå§ä¹Ÿå¾ˆçƒ­æƒ…ï¼Œä¸Šå‘¨æ—å¬äº†ä¸€æ¬¡ç»„ä¼šï¼Œç»„é‡Œæ°›å›´ä¹Ÿå¾ˆæ£’ã€‚é‚£å°±éšé‡è€Œå®‰å§(<em>^_^</em>)<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1603804400/IMG_1058_20201027-211306_vsrzgg.jpg" alt=""></p>
<p>åæœˆäºŒåäºŒæ—¥ï¼ŒUISTä¼šè®®åœ¨çº¿ä¸Šå¬å¼€ï¼Œå¯’ç ”çš„è®ºæ–‡ç»ˆäºå‘è¡¨å‡ºæ¥å•¦ï¼å›æƒ³é‚£æ®µæ—¶å…‰ï¼Œåˆè¾›è‹¦åˆå¼€å¿ƒã€‚</p>
<p>9.28å¼€å§‹åœ¨ä¸Šæµ·intelå®ä¹ ã€‚ç»„é‡Œåšquantize aware trainingçš„ï¼Œæ¥ä¹‹å‰æˆ‘å¯¹è¿™ä¸ªé¢†åŸŸä¸€æ— æ‰€çŸ¥ï¼ŒåªçŸ¥é“æ˜¯æœºå™¨å­¦ä¹ ä¼˜åŒ–ã€é¢è¯•çš„æ—¶å€™è§‰å¾—è¿™ä¸ªå·¥ä½œæŒºæœ‰æ„æ€çš„å°±æ¥äº†ã€‚æ¥ä¹‹åæ—¥å¸¸æ‡µé€¼ï¼Œç–¯ç‹‚è¡¥æ¦‚å¿µã€‚æœ€è¿‘å‡ å¤©ä¼šå†å†™ä¸€ç¯‡åšæ–‡è°ˆè°ˆè‡ªå·±å¯¹quantize aware trainingçš„ç†è§£ã€‚å®ä¹ é‡åˆ°çš„äººéƒ½å¾ˆå¥½ï¼Œè™½ç„¶ä»–ä»¬ä¸å¤ªä¼šè¡¨è¾¾ä½†æ˜¯æ—¶é—´ä¹…äº†è¿˜æ˜¯å¯ä»¥æ„Ÿå—åˆ°å¤§å®¶æ»¡æ»¡çš„å–„æ„â¤ã€‚æ„Ÿè§‰è‡ªå·±åˆèœåˆç‰›ã€‚ç›®å‰ä»ç„¶åœ¨é€‚åº”å®ä¹ çš„ç¯å¢ƒä¸­ï¼Œæ¯å¤©é—®è‡ªå·±æ— æ•°æ¬¡ï¼šâ€œæˆ‘æ˜¯è°ï¼Ÿæˆ‘åœ¨å“ªï¼Ÿæˆ‘è¦åšä»€ä¹ˆï¼Ÿâ€ã€‚ä½†è¿˜æ˜¯æ—¶å¸¸æ„Ÿåˆ°èŒ«ç„¶ï¼Œå¼€å§‹æ€€ç–‘äººç”Ÿï¼šæˆ‘æ˜¯ä¸æ˜¯ä¸é€‚åˆåšè¿™ç§å·¥ä½œï¼Ÿæˆ‘å¤§å­¦æœŸé—´æ˜¯ä¸æ˜¯è¿‡çš„å¤ªé¡ºåˆ©äº†æ²¡é‡åˆ°è¿‡ä¸€ç‚¹æŒ«æŠ˜ï¼Œæ‰å¯¼è‡´ç°åœ¨é‡åˆ°æŒ‘æˆ˜ä¹‹åéå¸¸éš¾å—ï¼Ÿæœ‰æ—¶å€™ä¹Ÿä¼šä¸Šå‡åˆ°å¼€å§‹æ€è€ƒäººç”Ÿçš„æ„ä¹‰( ï¹ ï¹ ) ~â†’å¯èƒ½æ˜¯æˆ‘ä¹¦è¯»çš„å¤ªå°‘ï¼Œå¯¹äºç¤¾ä¼šå’Œå¿ƒç†çš„è®¤çŸ¥ä¸å¤Ÿï¼Œæ‰ä¼šé™·å…¥è¿™æ ·çš„è¿·èŒ«å§ã€‚ä¹°äº†ä¸€äº›ä¹¦ï¼Œè¿˜æ˜¯è¦å¤šè¯»ä¹¦ï¼Œå°½é‡ä¸è¦è®©è‡ªå·±é™·åœ¨â€œä¹¦è¯»çš„å¤ªå°‘è€Œæƒ³å¾—å¤ªå¤šâ€çš„å›°å¢ƒä¸­ã€‚</p>
<p>åœ¨ä¸Šæµ·ç§Ÿçš„å°æˆ¿å­ç»è¿‡æˆ‘ä¸€ä¸ªæœˆä»¥æ¥çš„æ”¶æ‹¾ï¼Œå˜å¾—éå¸¸çš„æ¸©é¦¨å•¦ã€‚é˜³å…‰æ´’è¿›æ¥ï¼Œæ»¡å±‹å­éƒ½æ˜¯æ¸©æš–çš„å‘³é“ã€‚<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1603805430/E911F452FC56363BAD7FC64E944D825F_dfdzzj.jpg" alt=""></p>
<h3 id="ç¢ç¢å¿µ"><a href="#ç¢ç¢å¿µ" class="headerlink" title="ç¢ç¢å¿µ"></a>ç¢ç¢å¿µ</h3><p>ä»¿ä½›å›°åœ¨å›´åŸä¸­ï¼Œæ™šå®‰(ï¿£oï¿£) . z Z</p>
]]></content>
      <tags>
        <tag>LIFE</tag>
      </tags>
  </entry>
</search>
