<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2020/04/24/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Neural Approaches to Conversational AI</title>
    <url>/2020/04/25/Neural-Approaches-to-Conversational-AI/</url>
    <content><![CDATA[<h3 id="What’s-new"><a href="#What’s-new" class="headerlink" title="What’s new?"></a>What’s new?</h3><ol>
<li><strong>We group conversational systems into three categories: (1) question answering agents, (2) task-oriented dialogue agents, and (3)chatbots, with a unified view of optimal decision making</strong></li>
<li><strong>Draw connections between neural approaches to traditional ones</strong></li>
<li><strong>Present approaches to training dialogue agents using both supervised and reinforcement(++) learning.</strong></li>
<li><strong>Progress and challenges both in rearch community and industry.</strong></li>
</ol>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li><p>Why we get promising results?</p>
<ol>
<li>large amounts of data available for training.</li>
<li>breakthroughs in deep learning and reinforcement learning.</li>
</ol>
</li>
<li><p>A typical task-oriented dialogue agent is composed of four modules:<br>  <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587927050/1111_zxlmue.png" alt=""></p>
<ol>
<li>NLU(Understanding): identify user intents, extract associate info.</li>
<li>State Tracker: capture all essential info, track the dialogue state.</li>
<li>Dialogue Policy: select the next action based on the current state.</li>
<li>NLG(Generation): convert agent actions to natural language responses.</li>
</ol>
<ul>
<li>But recent trend: Develope fully data-driven systems by unifying these modules using a deep neural network that maps the user input to the agent output DIRECTLY.</li>
</ul>
</li>
<li><p>Difference in modular or not:</p>
<ul>
<li>Task-oriented bots:<ul>
<li>access to an external database</li>
<li>using a modular system</li>
</ul>
</li>
<li>Social chatbots:<ul>
<li>To be AI companions to humans with an emotional connection</li>
<li>mimic human conversation by training DNN-based response generation models on large amounts of human-human conversational data.</li>
<li>non-modular system</li>
</ul>
</li>
</ul>
</li>
<li><p>Dialogue can be formulated as a decision making process.</p>
<ul>
<li>hierarchy<ul>
<li>top level: selects what agent be active</li>
<li>low level: chooses primitive actions to complete the subtask</li>
</ul>
</li>
<li>Hierachical decision making processes can be cast in options over Markov Decision Processes(Sutton et al)<ul>
<li>This view has already been applied to some large-scale open-domain dialogue systems.</li>
</ul>
</li>
<li>If we view each option as an action, both top and low level processes can be natually captured by the reinforcement learning framework.<ul>
<li>Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.</li>
<li>The goal of dialogue learning is to find optimal policies to maximize expected rewards.</li>
<li>rewards functions:<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587945852/222_ctrk2x.png" alt=""></li>
<li><strong>controdictary rewards CPS for xiaoice?</strong><ul>
<li>Although incorporating many task-oriented and QA skills can reduce CPS in the short term since these skills help users accomplish tasks more efficiently by minimizing CPS, these new skills establish XiaoIce as an efficient and trustworthy personal assistant, thus strengthening the emotional bond with human users in the long run.</li>
</ul>
</li>
<li>limit of RL view:<ul>
<li>applying RL requires training the agents by interacting with real users, which can be expensive in many domains.</li>
<li>solution<ul>
<li>hybrid approach: combines the strengths of different ML methods.</li>
<li>For example, we might use imitation and/or supervised learning methods (if there is a large amount of human-human conversational corpus) to obtain a reasonably good agent before applying RL to continue improving it.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Symbolic V.S Neural approaches<br>  <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587950076/333_jcwtrl.png" alt=""></p>
<ul>
<li><p><strong>neural approaches</strong>:</p>
<ul>
<li><strong>can be trained in an end-to-end fasion</strong></li>
<li><strong>robust to paraphrase alternations(detecting and generating paraphrases)</strong></li>
<li><strong>weak in terms of execution efficiency and explicit interpretability</strong></li>
</ul>
</li>
<li><p><strong>symbolic approaches</strong></p>
<ul>
<li><strong>sensitive to paraphrase alternations</strong></li>
<li><strong>more interpretable and efficient in execution.</strong></li>
<li><strong>difficult to train</strong></li>
</ul>
</li>
<li><p>Symbolic approaches</p>
<ul>
<li>dominated for decades</li>
<li>resolve natural language ambiguity at different levels by mapping (or generating) a natural language sentence to (or from) a series of human-defined, unambiguous, symbolic representations, such as Part-Of-Speech (POS) tags, context free grammar, first-order predicate calculus.</li>
<li>now: have been adapted as a rich source of engineered features to be fed into a variety of machine learning models</li>
</ul>
</li>
<li><p>neural approaches</p>
<ul>
<li>do not rely on any human-defined symbolic representations</li>
<li>learn in a task- specific neural space where task-specific knowledge is implicitly represented as semantic concepts using low-dimensional continuous vectors.</li>
<li>steps:<ol>
<li>encoding symbolic user input and knowledge into their neural sematic representations( represent as vectors)</li>
<li>reasoning: to generate a system response based on input and system state.</li>
<li>decoding</li>
</ol>
<ul>
<li>the above three steps are stacked into a deep neural network trained in an end-to-end fastionl via back propagation.<ul>
<li>back propagation:<ul>
<li>a widely used algorithm in training feedforward neural networks for supervised learning. </li>
<li>In fitting a neural network, backpropagation computes the gradient of the loss function with respect to the weights of the network for a single input–output example, and does so efficiently, unlike a naive direct computation of the gradient with respect to each weight individually.</li>
<li>The backpropagation algorithm works by computing the gradient of the loss function with respect to each weight by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this is an example of dynamic programming.</li>
</ul>
</li>
<li>end-to-end causes: the focus has shifted to carefully tailoring the increasingly complex architecture of neural networks to the end application.</li>
</ul>
</li>
</ul>
</li>
<li>review: Although neural approaches have already been widely adopted in many AI tasks, including image processing, speech recognition and machine translation (e.g., Goodfellow et al., 2016), their impact on conversational AI has come somewhat more slowly.</li>
<li>addition merits: neural approaches provide a consistent representation for many modalities, capturing linguistic and non-linguistic (e.g., image and video (Mostafazadeh et al., 2017)) features in the same modeling framework.</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning Basics for Conversational AI</title>
    <url>/2020/04/26/Machine-Learning-Basics/</url>
    <content><![CDATA[<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p><strong>Mitchell</strong> defines: any computer program that improves its performance at some task T, measured by P, through experiences E.</p>
<ul>
<li>T:(in conversational AI: perform conversations with a user to fulfill the user’s goal.</li>
<li>P: cumulative reward<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1587945852/222_ctrk2x.png" alt=""></li>
<li>E: a set of dialogues</li>
</ul>
<h2 id="Surpervised-Learning"><a href="#Surpervised-Learning" class="headerlink" title="Surpervised Learning"></a>Surpervised Learning</h2><h4 id="A-common-recipe-of-building-an-ML-agent-using-supervised-learning-SL-consists-of"><a href="#A-common-recipe-of-building-an-ML-agent-using-supervised-learning-SL-consists-of" class="headerlink" title="A common recipe of building an ML agent using supervised learning (SL) consists of"></a>A common recipe of building an ML agent using supervised learning (SL) consists of</h4><ul>
<li>a dataset </li>
<li>The dataset consists of (x, y∗) pairs, where for each input x, there is a ground-truth output y∗. In QA, x consists of an input question and the documents from which an answer is generated, and y∗ is the desired answer provided by a knowledgeable external supervisor</li>
<li>a model</li>
<li>a cost function (a.k.a. loss function)<ul>
<li>The cost function is of the form L(y∗, f(x; θ))</li>
<li>L(.) is often designed as a smooth function(differentiable everywhere) of error.</li>
<li>A commonly used cost function that meets these criteria is the mean squared error (MSE)<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588012080/de_bccc3c.png" alt=""></li>
</ul>
</li>
<li>an optimization procedure<ul>
<li>The optimization can be viewed as a search algorithm to identify the best θ that <strong>minimize L(.)</strong>.<br>Given that L is differentiable, the most widely used optimization procedure for deep learning is mini-batch Stochastic Gradient Descent (SGD) which updates θ after each batch as <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588012262/SGD_yin3qj.png" alt=""> where N is the batch size and α the learning rate.</li>
</ul>
</li>
</ul>
<h4 id="Common-supervised-learning-metrics"><a href="#Common-supervised-learning-metrics" class="headerlink" title="Common supervised learning metrics"></a>Common supervised learning <strong>metrics</strong></h4><p>regression problems: mean squared error</p>
<ul>
<li><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588046494/MSE_uncxsu.png" alt=""></li>
</ul>
<p>classification problems</p>
<ul>
<li>binary classification: accuracy, precision, recall, F1 Score<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588048090/binary-classification-metrics_kefszn.png" alt=""></li>
<li>beyond binary: BLEU score</li>
</ul>
<h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><p>Define: In unexplored territories, the agent has to learn how to act by interacting with an unknown environment on its own. </p>
<h4 id="RL-V-S-SL"><a href="#RL-V-S-SL" class="headerlink" title="RL V.S SL:"></a>RL V.S SL:</h4><p>While SL learns from previous experiences provided by a knowledgeable external supervisor, RL learns by experiencing on its own.</p>
<h4 id="Feature-of-RL"><a href="#Feature-of-RL" class="headerlink" title="Feature of RL:"></a>Feature of RL:</h4><ol>
<li>Exploration-exploitation tradeoff. (???)</li>
</ol>
<ul>
<li>exploit: The agent has to exploit what it already knows in order to obtain high rewards.</li>
<li>explore: The agent has to explore unknown states and actions in order to make better action selections in the future.</li>
</ul>
<ol start="2">
<li><p>Delayed reward and temporal credit assignment.<br>The agent has to determine which of the actions in its sequence are to be credited with producing the eventual reward.</p>
</li>
<li><p>Partially observed states.<br>In many RL problems, the observation perceived from the environment at each step, e.g., user input in each dialogue turn, provides only partial information about the entire state of the environment based on which the agent selects the next action.<br>Neural approaches learn a deep neural network to represent the state by <strong>encoding all information</strong> observed at the current and past steps.</p>
</li>
</ol>
<h4 id="A-central-challenge-in-both-RL-and-SL-generalization"><a href="#A-central-challenge-in-both-RL-and-SL-generalization" class="headerlink" title="A central challenge in both RL and SL: generalization"></a>A central challenge in both RL and SL: <strong>generalization</strong></h4><p>the ability to perform well on unseen inputs.</p>
<ul>
<li>solution: neural approaches provide a potentially more effective solution by <strong>leveraging the representation</strong>(?) learning power of deep neural networks.</li>
</ul>
<h1 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h1><h4 id="Deep-learning-V-S-neural-network"><a href="#Deep-learning-V-S-neural-network" class="headerlink" title="Deep learning V.S neural network?"></a>Deep learning V.S neural network?</h4><p>DL involves training neural networks.</p>
<p><strong>Why Deep?</strong></p>
<p>The neural networks, in their original form, consisted of a single layer(i.e., the perceptron).</p>
<p>The perceptron is incapable of learning even simple functions such as logical XOR.</p>
<p>To solve the problem, we add hidden layers(<strong>Why hiden?</strong>) between input and output. –this is called MLP(multi-layer perceptron) or DNN(deep neural networks).</p>
<h2 id="commonly-used-DNNs-for-NLP-amp-IR"><a href="#commonly-used-DNNs-for-NLP-amp-IR" class="headerlink" title="commonly used DNNs for NLP &amp; IR"></a>commonly used DNNs for NLP &amp; IR</h2><h3 id="Softmax-function"><a href="#Softmax-function" class="headerlink" title="Softmax function"></a><strong>Softmax function</strong></h3><p>An activation function.</p>
<p>It outputs a vector that represents the probability distributions of a list of potential outcomes.</p>
<h3 id="normalization-step-taking-exponentials-sums-and-division"><a href="#normalization-step-taking-exponentials-sums-and-division" class="headerlink" title="normalization step: taking exponentials, sums and division."></a><strong>normalization step: taking exponentials, sums and division.</strong></h3><p>ex. Softmax function turns logits [2.0, 1.0, 0.1] into probabilities [0.7, 0.2, 0.1], and the probabilities sum to 1.<br><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588104301/softmax_wy6yoa.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">logits &#x3D; [2.0, 1.0, 0.1]</span><br><span class="line">exps &#x3D; [np.exp(i) for i in logits]</span><br><span class="line">sum_of_exps &#x3D; sum(exps)</span><br><span class="line">softmax &#x3D; [j&#x2F;sum_of_exps for j in exps]</span><br><span class="line">print(&quot;softmax:&#123;&#125;&quot;.format(softmax))</span><br></pre></td></tr></table></figure>

<p><em>Why we need exponents?</em></p>
<ul>
<li>Logits ranges from negative infinity to positive infinity. When logits are negative, adding it together does not give us the correct normalization. Exponentiate logitsturn them them zero or positive!</li>
</ul>
<p><em>Why special number e?</em></p>
<ul>
<li>e exponents also makes the math easier later! log(a*b)= log(a)+log(b)</li>
</ul>
<p><em>logits layer means the last neuron layer of neural network for classification task which produces raw prediction values.</em></p>
<p><em>Logits: numeric output of the last linear layer of a multi-class classification neural network. Before activation takes place.</em></p>
<p>Softmax function is <em>frequently appended to</em> the last layer of an image classification network such as cnn.</p>
<ul>
<li><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588105160/soft2_a3nsm6.png" alt=""></li>
</ul>
<h2 id="classical-ML-V-S-DL"><a href="#classical-ML-V-S-DL" class="headerlink" title="classical-ML V.S DL"></a>classical-ML V.S DL</h2><p><em>Ex: text classification</em></p>
<h3 id="classical-ML"><a href="#classical-ML" class="headerlink" title="classical ML:"></a>classical ML:</h3><ol>
<li>Map a text string to a vector representation <strong>x</strong>, using a set of <strong>hand-engineered</strong> features.</li>
<li>Learn a linear classifier with a softmax layer to compute the distribution.</li>
</ol>
<p><em>Design effort: feature engineering</em></p>
<h3 id="DL"><a href="#DL" class="headerlink" title="DL"></a>DL</h3><p>Jointly optimize the <em>feature representation</em> and <em>classification</em> using a DNN.</p>
<p><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588128439/ml-vs-dl_nel4rq.png" alt=""></p>
<p>DNN consists of two halves:</p>
<ol>
<li>top half: linear classifier, similar to classical ML.</li>
<li>The input vector of top half is <strong>not from hand-engineered features</strong>, but learned using the bottom half of the DNN.</li>
</ol>
<p><em>Design Effort: optimize DNN architectures for effective representation learning.</em></p>
<h2 id="Which-NN-neural-network-to-choose"><a href="#Which-NN-neural-network-to-choose" class="headerlink" title="Which NN(neural network) to choose?"></a>Which NN(neural network) to choose?</h2><p><strong>Depend on the type of linguistic structures that we hope to capture in the text.</strong></p>
<h3 id="Word-Embedding-layers"><a href="#Word-Embedding-layers" class="headerlink" title="Word Embedding layers"></a>Word Embedding layers</h3><h3 id="Define-word-embedding"><a href="#Define-word-embedding" class="headerlink" title="Define word embedding"></a>Define word embedding</h3><p>Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.</p>
<p>Word embeddings are in fact a class of techniques where individual words are represented as real-valued vectors in a predefined vector space. Each word is mapped to one vector and the vector values are learned in a way that resembles a neural network, <strong>based on the usage of the words.</strong></p>
<p>Each word is represented as a <strong>one hot</strong> vector, whose dimensionality <em>n</em> is the size of a pre-defined voca<br>bulary. The vocabulary is often too large. Word embedding model is to map each one-hot vector to a m-dimensional real-valued vector. m 《 n. The number of features is much smaller than the size of the vocabulary.</p>
<h3 id="one-hot"><a href="#one-hot" class="headerlink" title="one-hot"></a>one-hot</h3><p>EX1: Suppose you have ‘flower’ feature which can take values ‘daffodil’, ‘lily’, and ‘rose’. One hot encoding converts ‘flower’ feature to three features, ‘is_daffodil’, ‘is_lily’, and ‘is_rose’ which all are binary.</p>
<p>EX2: <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588178728/one-hot_qa7mmr.png" alt=""></p>
<p>Word embeddng is one of the key breakthroughs of DL on challenging NLP.  </p>
<ol>
<li><strong>low-dimensinal vector</strong>: the majority of neural network toolkits do not play well with very high-dimensional, sparse vectors</li>
<li><strong>dense vector</strong>:  it is worthwhile to provide a representation that is able to capture these similarities on features.</li>
</ol>
<h3 id="Word-embedding-algorithms"><a href="#Word-embedding-algorithms" class="headerlink" title="Word embedding algorithms"></a>Word embedding algorithms</h3><p><strong>Word embedding methods are learning process.</strong></p>
<p>They learn a <em>real-valued vector representation</em> for a predefined fixed sized vocabulary <em>from a corpus of text</em>.</p>
<p>Two types of learning process:</p>
<ol>
<li>Joint with neural network model on some task.</li>
<li>Unsupervised process, using document statistics.</li>
</ol>
<p>Three ways to learn a word embedding:</p>
<p><strong>1.Embedding layer</strong></p>
<p>It’s a word embedding, which is learned jointly with a <em>neural network model</em> on a <em>specific</em> natural language processing task(ex: language modeling or document classification).</p>
<p>It’s <em>used</em> on the front end of a neural network and is fit in a supervised way using a Backpropagation algorithm.</p>
<p>It requires that document text be cleaned and prepared such that each word is one-hot encoded.</p>
<ul>
<li>disadvantage: It requires a lot of training data and can be slow</li>
<li>advantage: It will learn an embedding both targeted to the <em>specific text data</em> and the <em>NLP task</em>.</li>
</ul>
<p><strong>2. Word2Vec</strong></p>
<p>It is <strong>effient</strong>, good at capturing syntactic and semantic regularities, learns a <em>standalone</em> word embedding from a text corpus.</p>
<pre><code>low space and time complexity
more dimensions
much larger corpora of text </code></pre><p><strong>Ex: King - man + woman = Queen.</strong></p>
<p>– Word2Vec involved analysis of the learned vectors and the exploration of vector math on the representations of words. </p>
<p><em>Two different models</em>:</p>
<ul>
<li><p>CBOW(continuous Bag-of-Words) model</p>
<p>  CBOW learns the embedding by predicting the current word based on its context.</p>
</li>
<li><p>Continuous Skip-Gram Model</p>
<p>  It learns by predicting the surrounding words given a current word.</p>
</li>
</ul>
<p><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588197753/word2vec_j3hnqr.png" alt=""></p>
<p><strong>Size of sliding winodw</strong><br>The context is defined by a window of neighboring words. This window is a configurable parameter of the model.</p>
<p>Large windows tend to produce more topical similarities, while smaller windows tend to produce more functional and syntactic similarities.</p>
<p><strong>3.GloVe: The Global Vectors for Word Representation</strong></p>
<p>It is an extension to the word2vec method for efficiently learning word vectors. GloVe is an approach to marry both the <em>global statistics of matrix factorization techniques</em> like LSA with the <em>local context-based learning</em> in word2vec.</p>
<ul>
<li>LSA(latent semantic analysis): It’s for analyzing relationships between a set of documents and the terms they contain by <em>producing a set of concepts related to the documents and terms</em>. LSA assumes that <em>words that are close in meaning will occur in similar pieces of text</em>. A matrix containing word counts per document (rows represent unique words and columns represent each document). Documents are then compared by taking the cosine of the angle between the two vectors (or the dot product between the normalizations of the two vectors) formed by any two columns. Values close to 1 represent very similar documents while values close to 0 represent very dissimilar documents</li>
</ul>
<p>Rather than using a window to define local context, <em>GloVe constructs an explicit word-context or word co-occurrence matrix using statistics across the whole text corpus.</em></p>
<p>GloVe performs well at word analogy, word similarity, and named entity recognition tasks.</p>
<h3 id="Learn-OR-reuse-word-embedding"><a href="#Learn-OR-reuse-word-embedding" class="headerlink" title="Learn OR reuse word embedding?"></a>Learn OR reuse word embedding?</h3>]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>[BASIC]Word Embedding</title>
    <url>/2020/04/29/BASIC-Word-Embedding/</url>
    <content><![CDATA[<h1 id="Word-Embedding-layers"><a href="#Word-Embedding-layers" class="headerlink" title="Word Embedding layers"></a>Word Embedding layers</h1><h2 id="Define-word-embedding"><a href="#Define-word-embedding" class="headerlink" title="Define word embedding"></a>Define word embedding</h2><p>Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.</p>
<p>Word embeddings are in fact a class of techniques where individual words are represented as real-valued vectors in a predefined vector space. Each word is mapped to one vector and the vector values are learned in a way that resembles a neural network, <strong>based on the usage of the words.</strong></p>
<p>Each word is represented as a <strong>one hot</strong> vector, whose dimensionality <em>n</em> is the size of a pre-defined voca<br>bulary. The vocabulary is often too large. Word embedding model is to map each one-hot vector to a m-dimensional real-valued vector. m 《 n. The number of features is much smaller than the size of the vocabulary.</p>
<h3 id="one-hot"><a href="#one-hot" class="headerlink" title="one-hot"></a>one-hot</h3><p>EX1: Suppose you have ‘flower’ feature which can take values ‘daffodil’, ‘lily’, and ‘rose’. One hot encoding converts ‘flower’ feature to three features, ‘is_daffodil’, ‘is_lily’, and ‘is_rose’ which all are binary.</p>
<p>EX2: <img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588178728/one-hot_qa7mmr.png" alt=""></p>
<p>Word embeddng is one of the key breakthroughs of DL on challenging NLP.  </p>
<ol>
<li><strong>low-dimensinal vector</strong>: the majority of neural network toolkits do not play well with very high-dimensional, sparse vectors</li>
<li><strong>dense vector</strong>:  it is worthwhile to provide a representation that is able to capture these similarities on features.</li>
</ol>
<h2 id="Word-embedding-algorithms"><a href="#Word-embedding-algorithms" class="headerlink" title="Word embedding algorithms"></a>Word embedding algorithms</h2><p><strong>Word embedding methods are learning process.</strong></p>
<p>They learn a <em>real-valued vector representation</em> for a predefined fixed sized vocabulary <em>from a corpus of text</em>.</p>
<p>Two types of learning process:</p>
<ol>
<li>Joint with neural network model on some task.</li>
<li>Unsupervised process, using document statistics.</li>
</ol>
<p>Three ways to learn a word embedding:</p>
<p><strong>1.Embedding layer</strong></p>
<p>It’s a word embedding, which is learned jointly with a <em>neural network model</em> on a <em>specific</em> natural language processing task(ex: language modeling or document classification).</p>
<p>It’s <em>used</em> on the front end of a neural network and is fit in a supervised way using a Backpropagation algorithm.</p>
<p>It requires that document text be cleaned and prepared such that each word is one-hot encoded.</p>
<ul>
<li>disadvantage: It requires a lot of training data and can be slow</li>
<li>advantage: It will learn an embedding both targeted to the <em>specific text data</em> and the <em>NLP task</em>.</li>
</ul>
<p><strong>2. Word2Vec</strong></p>
<p>It is <strong>effient</strong>, good at capturing syntactic and semantic regularities, learns a <em>standalone</em> word embedding from a text corpus.</p>
<pre><code>low space and time complexity
more dimensions
much larger corpora of text </code></pre><p><strong>Ex: King - man + woman = Queen.</strong></p>
<p>– Word2Vec involved analysis of the learned vectors and the exploration of vector math on the representations of words. </p>
<p><em>Two different models</em>:</p>
<ul>
<li><p>CBOW(continuous Bag-of-Words) model</p>
<p>  CBOW learns the embedding by predicting the current word based on its context.</p>
</li>
<li><p>Continuous Skip-Gram Model</p>
<p>  It learns by predicting the surrounding words given a current word.</p>
</li>
</ul>
<p><img src="https://res.cloudinary.com/dmfrqkuif/image/upload/v1588197753/word2vec_j3hnqr.png" alt=""></p>
<p><strong>Size of sliding winodw</strong><br>The context is defined by a window of neighboring words. This window is a configurable parameter of the model.</p>
<p>Large windows tend to produce more topical similarities, while smaller windows tend to produce more functional and syntactic similarities.</p>
<p><strong>3.GloVe: The Global Vectors for Word Representation</strong></p>
<p>It is an extension to the word2vec method for efficiently learning word vectors. GloVe is an approach to marry both the <em>global statistics of matrix factorization techniques</em> like LSA with the <em>local context-based learning</em> in word2vec.</p>
<ul>
<li>LSA(latent semantic analysis): It’s for analyzing relationships between a set of documents and the terms they contain by <em>producing a set of concepts related to the documents and terms</em>. LSA assumes that <em>words that are close in meaning will occur in similar pieces of text</em>. A matrix containing word counts per document (rows represent unique words and columns represent each document). Documents are then compared by taking the cosine of the angle between the two vectors (or the dot product between the normalizations of the two vectors) formed by any two columns. Values close to 1 represent very similar documents while values close to 0 represent very dissimilar documents</li>
</ul>
<p>Rather than using a window to define local context, <em>GloVe constructs an explicit word-context or word co-occurrence matrix using statistics across the whole text corpus.</em></p>
<p>GloVe performs well at word analogy, word similarity, and named entity recognition tasks.</p>
]]></content>
      <tags>
        <tag>BASIC</tag>
      </tags>
  </entry>
</search>
